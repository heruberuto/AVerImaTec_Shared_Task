{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ecea419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ques_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "evid_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "verdict_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "justi_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intermediate_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "c293223f-69d6-4974-8188-c4f563f10851",
       "rows": [
        [
         "0",
         "1.0",
         "1.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. 2. The question is covered by the second reference question. 3. The question is not covered by any reference question. 4. The question is covered by the second reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is covered by the second reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the second predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Multiple independent reports identify the woman in the photo as 101-year-old Rosa Camfield holding her great-granddaughter Kaylee. 2. Viral claims saying she gave birth at 101 to her 17th child are false. 3. No medical or news source documents a 101-year-old giving birth. 4. Record-holder data place the oldest mothers decades younger than 101.\\n[REF_FACT]: 1. The claim that the woman has given birth to her 17th child is successfully refuted. 2. Evidence shows she had only three children. 3. She was photographed holding a great-granddaughter prior to her death.\\n[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The fact is covered by the first fact in the reference fact set, as it states the claim is refuted. 2. The fact is consistent with the second fact in the reference fact set. 3. The fact is covered by the third fact in the reference set.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The fact is covered by the first fact in the predicted fact set. 2. The fact is not directly covered, but implied by the predicted fact set. 3. The fact is covered by the first fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 3, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 2; (PRED_1,REF_1);(PRED_10,REF_2)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence supports the first fact in the reference evidence as it identifies the woman as Rosa Camfield. 2. The tenth fact in the predicted evidence supports the second fact in the reference evidence as it lists her family members. 3. The remaining facts in the predicted evidence do not find direct support in the reference evidence.\\n[REF in PRED]: 2; (REF_1,PRED_1);(REF_2,PRED_10)\\n[REF in PRED Exp]: 1. The first fact in the reference evidence is supported by the first fact in the predicted evidence, which identifies the woman as Rosa Camfield. 2. The second fact in the reference evidence is supported by the tenth fact in the predicted evidence, which lists her family members. 3. The other facts in the predicted evidence contain information that is not found in the reference evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_10', 'REF_2'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_1', 'PRED_1'], 'score': '10'}, {'info': ['REF_2', 'PRED_10'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '(REF_1,PRED_1);(REF_2,PRED_10)', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_10,REF_2)'}}"
        ],
        [
         "1",
         "1.0",
         "0.25",
         "1",
         "0.6666666666666661",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first question is covered by the first reference question. 2. The question is not covered by any reference question. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 4\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the second predicted question. 3. The question is not covered by any predicted question. 4. The question is not covered by any predicted question.', 'ques_score': {'ref_in_pred': 4, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Reports and matching photos from multiple outlets show that the images are from Morbi Civil Hospital in Gujarat. 2. Morbi Civil Hospital was given a makeover before PM Modi’s visit after the October 2022 Morbi bridge collapse. 3. No source links these images to any Cuttack hospital or to Modi’s June 2023 visit to meet victims of the Odisha train accident. 4. The claim misattributes older Morbi hospital renovation images to a different location and event.\\n[REF_FACT]: 1. The images were taken in November, 2022 in preparation for a Modi visit. 2. The images were taken after a bridge collapse. 3. The Odisha train incident did not happen until June of 2023.\\n[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. This fact is consistent with the first and second facts in the reference fact set. 3. The fact is not covered by the reference fact set. 4. The fact is not covered by the reference fact set.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The fact is covered by the second fact in the predicted fact set. 2. The fact is covered by the second fact in the predicted fact set. 3. The fact is not covered by the predicted fact set.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 4; (PRED_1,REF_1);(PRED_3,REF_3);(PRED_7,REF_3);(PRED_10,REF_3)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence matches the first fact in the reference evidence. 2. The third fact is supported by the third fact in the reference evidence. 3. The seventh fact is supported by the third fact in the reference evidence. 4. The tenth fact is supported by the third fact in the reference evidence.\\n[REF in PRED]: 1; (REF_4,PRED_4)\\n[REF in PRED Exp]: 1. The fourth fact in the reference evidence is supported by the fourth fact in the predicted evidence. 2. The second fact in the reference evidence is not mentioned in the predicted evidence. 3. The third fact in the reference evidence is mentioned in multiple predicted facts, like the third, seventh and tenth.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_3', 'REF_3'], 'score': '10'}, {'info': ['PRED_7', 'REF_3'], 'score': '10'}, {'info': ['PRED_10', 'REF_3'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_4', 'PRED_4'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 4, 'detailed_ref_in_pred': '(REF_4,PRED_4)', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_3,REF_3);(PRED_7,REF_3);(PRED_10,REF_3)'}}"
        ],
        [
         "2",
         "0.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': \"[PRED in REF]: 0\\n[PRED in REF Exp]: None of the predicted questions are covered by the reference questions. The predicted questions focus on verifying claims about hospital renovations and a Prime Minister's visit, while the reference questions ask about the identity of stores and a company.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: None of the reference questions are covered by the predicted question set. The reference questions ask about the identity of stores and a company, while the predicted questions focus on verifying claims about hospital renovations and a Prime Minister's visit.\", 'ques_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Reports and matching photos from multiple outlets show that the images of workers repainting walls and fixing tiles are from Morbi Civil Hospital in Gujarat, which was given a makeover before PM Modi’s visit after the October 2022 Morbi bridge collapse. No source links these images to any Cuttack hospital or to Modi’s June 2023 visit to meet victims of the Odisha train accident. The claim misattributes older Morbi hospital renovation images to a different location and event, so it is refuted.\\n[REF]: The claim is refuted by proving that the images were created with AI by Waster_Space for satirical purposes.\\n[PRED_FACT]: 1. Reports and photos show the images are from Morbi Civil Hospital in Gujarat. 2. The hospital was renovated before PM Modi’s visit after the October 2022 Morbi bridge collapse. 3. No source links the images to a Cuttack hospital or Modi’s June 2023 visit. 4. The claim misattributes the images to a different location and event.\\n[REF_FACT]: 1. The images were created with AI by Waster_Space. 2. The images were created for satirical purposes.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set. 4. The fact is not covered by the reference fact set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact. 2. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence discusses hospital makeovers related to PM Modi’s visits, while the reference evidence is about a retail company and AI-generated images. No overlap in content. 2. The predicted evidence focuses on factual reporting regarding hospital conditions and image origins, whereas the reference describes artificially generated images. No connection. 3. The predicted evidence provides specific details about the Morbi Civil Hospital and Cuttack hospital, while the reference describes a completely different subject matter: Hobby Lobby and its depiction in AI images. No shared information. 4. The predicted evidence centers around verifying the authenticity of images related to hospital renovations, while the reference presents a description of AI-created images. No overlap. 5. The predicted evidence details observations about hospital makeovers and relates them to specific events, whereas the reference describes the creation of fictional retail environments using AI. No connection. 6. Similar to point 5, the predicted evidence focuses on a real-world event and image analysis, while the reference presents an unrelated AI-generated scenario. No overlap. 7. The predicted evidence offers conclusions about image authenticity and their connection to specific locations, while the reference provides a description of an AI-created image. No shared content. 8. The predicted evidence discusses the timeline of images relating to the Morbi bridge collapse, and the reference details AI-generated images. No common details. 9. The predicted evidence explains the context of PM Modi’s visit and the situation with the bridge collapse, while the reference is irrelevant. 10. The predicted evidence addresses the origin and timing of images, while the reference describes a completely different scenario. No common information.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence discusses Hobby Lobby and AI-generated images, which are not mentioned or addressed in any way in the predicted evidence. 2. The predicted evidence focuses on verifying the origin of images and hospital makeovers, while the reference provides information about a retail store and fictional imagery. No overlap. There is no relevant information within the predicted evidence to support the reference evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "3",
         "0.33333333333333304",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. 2. The question is not covered by any reference question. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is covered by the first reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The question is covered by the first and sixth predicted question. 2. The question is covered by the first and sixth predicted question. 3. The question is not covered by any predicted question.', 'ques_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Reverse-image search shows that the image predates the June 2023 disappearance of the Titan and originates from Titanic-themed artwork/graphics published in 2012, not from the search operation. News reports on the Titan search describe the difficulty of locating the submersible and do not mention any photograph of it near the wreck. Therefore, the image does not show the missing submersible Titan near the Titanic wreckage.\\n[REF]: The claim is refuted initially by proving that the Titan imploded and, secondly, by proving that the image shows the Alvin during an exploration dive to the Titanic.\\n[PRED_FACT]: 1. The image predates the June 2023 disappearance of the Titan. 2. The image originates from Titanic-themed artwork/graphics published in 2012. 3. The image is not from the search operation. 4. News reports on the Titan search describe the difficulty of locating the submersible. 5. News reports do not mention any photograph of it near the wreck. 6. The image does not show the missing submersible Titan near the Titanic wreckage.\\n[REF_FACT]: 1. The Titan imploded. 2. The image shows the Alvin during an exploration dive to the Titanic.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by nor similar to any reference fact. 3. The fact is not covered by nor similar to any reference fact. 4. The fact is not covered by nor similar to any reference fact. 5. The fact is not covered by nor similar to any reference fact. 6. The fact is not covered by nor similar to any reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by the predicted fact set.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence discusses a viral image and its origin, while the reference evidence focuses on the discovery of debris and potential causes of the Titan's implosion. No overlap exists. 2. The predicted evidence does not mention the specific debris found (titanium nose cone, tail piece) or their location relative to the Titanic. 3. The reference evidence discusses a 1986 exploration with the submersible Alvin, which is not discussed in the predicted evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence’s claim about the Titan's likely fate (snagged or imploded) is not addressed in the predicted evidence. 2. The reference evidence mentions specific debris found near the Titanic, but the predicted evidence doesn't discuss any debris. 3. The reference evidence's mention of the 1986 exploration is not addressed in the predicted evidence.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "4",
         "1.0",
         "0.0",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second reference question. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is covered by the first predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. The AFPI document does not definitively prove that extra ballots were counted. 2. The AFPI document describes a “potential 8,241‑vote discrepancy” between registered voters recorded as voting and ballots counted. 3. Arizona election materials emphasize accurate, audited counts and do not report a statewide situation where thousands more ballots than voters were recorded. 4. No independent official or audit source in the evidence accepts or validates AFPI’s figure as proof of surplus ballots. 5. The user’s claim overstates both the certainty and meaning of the study.\\n[REF_FACT]: 1. The information provided only states the source of the study. 2. There is no evidence that the claim is accurate. 3. There is no evidence that the claim is unbiased. 4. There is no evidence that the claim is based on fact.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact is covered by the reference fact set because it states that the provided information only mentions the source of the study.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact. 2. The fact is not covered by nor similar to any predicted fact. 3. The fact is not covered by nor similar to any predicted fact. 4. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence does not mention the number of voters in Arizona during the 2022 midterm election. 2. The predicted evidence does not mention John Lott as one of the authors.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence. 2. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "5",
         "0.5",
         "0.33333333333333304",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 4\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. 2. The question is covered by the third reference question. 3. The question is covered by the fourth reference question. 4. The question is covered by the fourth reference question. 5. The question is covered by the fifth reference question. 6. The question is not covered by any reference question. 7. The question is covered by the sixth reference question. 8. The question is covered by the fourth reference question. 9. The question is not covered by any reference question. 10. The question is covered by the fourth reference question.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is not covered by any predicted question. 3. The question is covered by the first predicted question. 4. The question is covered by the fourth and fifth predicted questions. 5. The question is covered by the fifth predicted question. 6. The question is not covered by any predicted question.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 4, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Reliable fact-checking and news reports about the June 2023 Balasore, Odisha multi-train collision confirm that the prominent white building near the crash site seen in aerial images is the Bahanaga ISKCON temple, not a mosque. Journalists on the ground and temple authorities verified this, and the fact-check explicitly states that social media users falsely claimed it was a mosque. No provided source supports the assertion that the crash happened near a mosque, so the claim is refuted.\\n[REF]: The claim is refuted by proving that the structure near the wreckage is a Krishna Consciousness temple, and not a mosque. The refutation is bolstered with a statement from Odisha police requesting cessation of the rumors.\\n[PRED_FACT]: 1. The prominent white building near the crash site is the Bahanaga ISKCON temple. 2. Journalists on the ground and temple authorities verified this. 3. Social media users falsely claimed it was a mosque. 4. No provided source supports the assertion that the crash happened near a mosque.\\n[REF_FACT]: 1. The structure near the wreckage is a Krishna Consciousness temple. 2. The claim is refuted. 3. Odisha police requested cessation of the rumors.\\n[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is covered by the first fact in the reference fact set. 3. The fact is covered by the second and third fact in the reference fact set. 4. The fact is not covered by the reference fact set.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The fact is covered by the first fact in the predicted fact set. 2. The fact is covered by the fourth fact in the predicted fact set. 3. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 3, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 5; (PRED_1,REF_1);(PRED_3,REF_3);(PRED_4,REF_5);(PRED_5,REF_4);(PRED_7,REF_6)\\n[PRED in REF Exp]: 1. The predicted fact aligns with the first fact in the reference set. 2. The predicted fact aligns with the third fact in the reference set. 3. The predicted fact aligns with the fifth fact in the reference set. 4. The predicted fact aligns with the fourth fact in the reference set. 5. The predicted fact aligns with the sixth fact in the reference set.\\n[REF in PRED]: 2; (REF_2,PRED_2);(REF_3,PRED_1)\\n[REF in PRED Exp]: 1. The second reference fact mentions the date of the claim and the predicted second fact gives the death toll. 2. The third reference fact mentions the date and the predicted first fact matches.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_3', 'REF_3'], 'score': '10'}, {'info': ['PRED_4', 'REF_5'], 'score': '10'}, {'info': ['PRED_5', 'REF_4'], 'score': '10'}, {'info': ['PRED_7', 'REF_6'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_2', 'PRED_2'], 'score': '10'}, {'info': ['REF_3', 'PRED_1'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 2, 'pred_in_ref': 5, 'detailed_ref_in_pred': '(REF_2,PRED_2);(REF_3,PRED_1)', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_3,REF_3);(PRED_4,REF_5);(PRED_5,REF_4);(PRED_7,REF_6)'}}"
        ],
        [
         "6",
         "1.0",
         "0.33333333333333304",
         "0",
         "0.5",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first reference question. 3. The question is covered by the third reference question. 4. The question is not covered by any reference question. 5. The question is covered by the first reference question. 6. The question is covered by the first reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is covered by the first and sixth predicted question. 2. The question is not covered by any predicted question. 3. The question is covered by the third and fourth predicted questions.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: The image’s county shapes and red/blue pattern match the standardized 2020 California presidential election results map on Wikimedia Commons, which is explicitly based on certified data from the state (via Dave Leip’s Atlas). No evidence in the provided sources suggests that the county-level winner pattern in that map deviates from the certified results, so it is reasonable to conclude that the depicted map reflects California’s certified 2020 presidential election outcome.\\n[REF]: The claim is refuted by showing the actual 2020 certified results map from California and by proving that a Republican candidate has not won the state since 1988.\\n[PRED_FACT]: 1. The image’s county shapes and red/blue pattern match the standardized 2020 California presidential election results map on Wikimedia Commons. 2. The map on Wikimedia Commons is based on certified data from the state. 3. No evidence suggests the county-level winner pattern deviates from the certified results.\\n[REF_FACT]: 1. The claim is refuted by showing the actual 2020 certified results map from California. 2. A Republican candidate has not won the state since 1988.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first fact in the predicted fact set is covered by the first fact in the reference set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The fact is similar to the first fact in the predicted fact set. 2. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 3; (PRED_1,REF_1);(PRED_3,REF_3);(PRED_10,REF_1)\\n[PRED in REF Exp]: 1. The predicted evidence claims that the map reflects the certified results of the 2020 presidential election, and the reference evidence confirms that Joe Biden won California in the 2020 election with over 60% of the vote. 2. The predicted evidence asserts that the map shows a pattern of red and blue counties, which aligns with the reference evidence's description of the map's appearance. 3. The predicted evidence suggests the image matches the 2020 election map, which is similar to what's stated in the reference.\\n[REF in PRED]: 1; (REF_3,PRED_3)\\n[REF in PRED Exp]: 1. The reference evidence states the map of the 2020 election results looked like [IMG_2], which aligns with the predicted evidence's detailed analysis of the map. 2. No other information can be found in the predicted evidence set.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_3', 'REF_3'], 'score': '10'}, {'info': ['PRED_10', 'REF_1'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_3', 'PRED_3'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 3, 'detailed_ref_in_pred': '(REF_3,PRED_3)', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_3,REF_3);(PRED_10,REF_1)'}}"
        ],
        [
         "7",
         "0.0",
         "0.0",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 0\\n[PRED in REF Exp]: None of the predicted questions are covered by any reference question. The predicted questions are all about verifying a map related to the 2020 US presidential election in California, while the reference questions are about a damaged truck and an explosion involving a Kamaz tanker in Ukraine.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: None of the reference questions are covered by the predicted questions. The reference questions focus on details regarding a specific incident (explosion of a Kamaz tanker), whereas the predicted questions delve into the verification of an election map.', 'ques_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: The image’s county shapes and red/blue pattern match the standardized 2020 California presidential election results map on Wikimedia Commons, which is explicitly based on certified data from the state (via Dave Leip’s Atlas). No evidence in the provided sources suggests that the county-level winner pattern in that map deviates from the certified results, so it is reasonable to conclude that the depicted map reflects California’s certified 2020 presidential election outcome.\\n[REF]: Based on evidence, the image shows a KamAZ 6×6 tanker that was blown up in Chernihiv Oblast on 28 February 2022. Moreover, according to a legitimate source that reports Russian losses, the KamAZ 6x6 tanker was marked captured and damaged on 28 February 2022 in Chernihiv Oblast.\\n[PRED_FACT]: 1. The image’s county shapes and red/blue pattern match the standardized 2020 California presidential election results map on Wikimedia Commons. 2. The map on Wikimedia Commons is based on certified data from the state. 3. No evidence suggests that the county-level winner pattern deviates from the certified results.\\n[REF_FACT]: 1. The image shows a KamAZ 6×6 tanker that was blown up in Chernihiv Oblast on 28 February 2022. 2. The KamAZ 6x6 tanker was marked captured and damaged on 28 February 2022 in Chernihiv Oblast.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_5,REF_6)\\n[PRED in REF Exp]: 1. The claim asserts that the shown county-level red/blue map of California reflects (i.e., matches) the state\\'s certified results from the 2020 presidential election. No relevant information in the reference evidence. 2. Yes. Wikimedia Commons hosts a map titled \"California Presidential Election Results 2020\" that is explicitly based on official results (Dave Leip’s Atlas using California Secretary of State data) and is used as a reference county-level results map. No relevant information in the reference evidence. 3. Yes. The reference map shows most northern and interior counties in red, with clusters of blue counties along major urban and coastal areas such as the Bay Area, Los Angeles region and a few others. No relevant information in the reference evidence. 4. Yes. The counties’ shapes and the overall distribution of red and blue areas in the image match the standardized California county map used in the 2020 presidential results map, indicating it is a cropped portion of such a map. No relevant information in the reference evidence. 5. Yes. The California Secretary of State certified the 2020 election results, including presidential results, after all 58 counties reported their final tallies. No relevant information in the reference evidence. 6. Yes. The certified results delivered California’s electoral votes to Joe Biden as part of his 306–232 Electoral College victory over Donald Trump. No relevant information in the reference evidence. 7. Yes. The file description states it is the \"2020 United States presidential election in California by county\" and cites Dave Leip’s Atlas, which itself uses official state results. No relevant information in the reference evidence. 8. No. The revision history discussions concern minor percentage adjustments (e.g., Biden’s exact share in Alameda County) but do not indicate that the county winner coloring or overall county results pattern is inconsistent with the certified outcomes. No relevant information in the reference evidence. 9. No. The sources only show or reference maps consistent with the pattern where most inland counties are red and major urban/coastal counties are blue for the 2020 presidential election. No relevant information in the reference evidence. 10. Yes. Since the provided image matches the standardized county-level 2020 results map that is based on certified data, it can be inferred that it reflects the certified 2020 presidential election results in California. No relevant information in the reference evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence. 2. No relevant evidence could be found in the predicted evidence. 3. No relevant evidence could be found in the predicted evidence. 4. No relevant evidence could be found in the predicted evidence. 5. No relevant evidence could be found in the predicted evidence. 6. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_5', 'REF_6'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_5,REF_6)'}}"
        ],
        [
         "8",
         "0.0",
         "0.0",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 0\\n[PRED in REF Exp]: 1. No similar questions to this question could be found in the reference question set. 2. No similar questions to this question could be found in the reference question set. 3. No similar questions to this question could be found in the reference question set. 4. No similar questions to this question could be found in the reference question set. 5. No similar questions to this question could be found in the reference question set. 6. No similar questions to this question could be found in the reference question set. 7. No similar questions to this question could be found in the reference question set. 8. No similar questions to this question could be found in the reference question set. 9. No similar questions to this question could be found in the reference question set. 10. No similar questions to this question could be found in the reference question set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. No similar questions to this question could be found in the predicted question set. 2. No similar questions to this question could be found in the predicted question set. 3. No similar questions to this question could be found in the predicted question set. 4. No similar questions to this question could be found in the predicted question set. 5. No similar questions to this question could be found in the predicted question set.', 'ques_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: The image’s county shapes and red/blue pattern match the standardized 2020 California presidential election results map on Wikimedia Commons, which is explicitly based on certified data from the state (via Dave Leip’s Atlas). No evidence in the provided sources suggests that the county-level winner pattern in that map deviates from the certified results, so it is reasonable to conclude that the depicted map reflects California’s certified 2020 presidential election outcome.\\n[REF]: The claim is successfully refuted by proving that the image was taken in 2015 and depicts a naked protest of inadequate police services, not a 2023 public parade for gospel preaching.\\n[PRED_FACT]: 1. The image’s county shapes and red/blue pattern match the standardized 2020 California presidential election results map on Wikimedia Commons. 2. The map is based on certified data from the state via Dave Leip’s Atlas. 3. No evidence suggests that the county-level winner pattern deviates from the certified results. 4. The depicted map reflects California’s certified 2020 presidential election outcome.\\n[REF_FACT]: 1. The image was taken in 2015. 2. The image depicts a naked protest of inadequate police services. 3. The image is not a 2023 public parade for gospel preaching.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set. 4. The fact is not covered by the reference fact set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by nor similar to any predicted fact. 3. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence focuses on verifying the accuracy of a map related to the 2020 California presidential election, while the reference evidence discusses a claim made on a specific date, an article in India Today, the location where an image was taken, and the reason people were naked in the image. There is no overlap in content.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence contains information about a claim date, a news article, a location, and a protest, none of which are addressed or supported by the predicted evidence's detailed analysis of a map's accuracy and connection to certified election results.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "9",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second reference question. 3. The question is covered by the first reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is covered by the first reference question. 8. The question is not covered by any reference question. 9. The question is covered by the second reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the third, fifth, sixth and eighth predicted question. 2. The question is covered by the second and ninth predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Sources attribute the likely oldest olive tree to Vouves in Crete, and mention several other competing ancient trees in Turkey, Lebanon, and the Bethlehem area. They do not identify any olive tree in Jerusalem as the world’s oldest or as being over 3,000 years old; Gethsemane trees are dated to about 900 years. The image used in the claim corresponds to the Vouves tree in Crete, not a Jerusalem tree. Therefore, the statement that the world’s oldest olive tree is in Jerusalem and over 3,000 years old is refuted by the available evidence.\\n[REF]: The claim is successfully refuted by proving that the tree in the image is a 3500-year-old tree in Greece.\\n[PRED_FACT]: 1. The likely oldest olive tree is in Vouves in Crete. 2. Several other competing ancient trees are in Turkey, Lebanon, and the Bethlehem area. 3. No olive tree in Jerusalem is identified as the world’s oldest or over 3,000 years old. 4. Gethsemane trees are dated to about 900 years. 5. The image corresponds to the Vouves tree in Crete.\\n[REF_FACT]: 1. The tree in the image is a 3500-year-old tree in Greece.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the tree is in Greece is consistent with the predicted fact that it is in Crete.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by any fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_2,REF_2)\\n[PRED in REF Exp]: 1. The second fact in the predicted evidence supports the second fact in the reference evidence, both stating the oldest olive tree is located in Greece.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence to support the first fact in the reference evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_2', 'REF_2'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_2,REF_2)'}}"
        ],
        [
         "10",
         "1.0",
         "0.25",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first reference question. 3. The question is covered by the third reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is covered by the fourth reference question. 7. The question is covered by the fourth reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 4\\n[REF in PRED Exp]: 1. The question is covered by the second predicted question. 2. The question is not covered by any predicted question. 3. The question is covered by the third predicted question. 4. The question is covered by the seventh predicted question.', 'ques_score': {'ref_in_pred': 4, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. The man in the image is ex-opposition supporter Ny Nak. 2. The photo is from the 2023 Cambodia national election. 3. He did not vote or get his finger inked. 4. His reason was low voter turnout. 5. The provided sources describe Cambodia’s election context, inking practices, boycott campaigns, and repression. 6. None of the sources identify the person in the photo, date the image, or report on Ny Nak’s personal voting behavior or motivations. 7. The image alone cannot conclusively show whether his finger is inked or why he did or did not vote.\\n[REF_FACT]: 1. Ny Nak did vote in the 2023 election. 2. Ny Nak is incorrectly identified as \"very much at odds with the royal government.\" 3. There is no metadata that indicates the claim date.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the claim date isn\\'t available is indirectly supported by the fact that the sources don\\'t provide that information (fact 6).\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact that Ny Nak voted is directly contradicted by the predicted fact set. 2. The fact about the incorrect identification is not covered by the predicted fact set. 3. The fact about the lack of metadata is not covered by the predicted fact set.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_3,REF_2)\\n[PRED in REF Exp]: 1. The fact is similar to the second reference fact.\\n[REF in PRED]: 1; (REF_3,PRED_1)\\n[REF in PRED Exp]: 1. The first fact in the predicted evidence has similar meaning to the third fact in the reference evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_3', 'REF_2'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_3', 'PRED_1'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '(REF_3,PRED_1)', 'detailed_pred_in_ref': '(PRED_3,REF_2)'}}"
        ],
        [
         "11",
         "0.2",
         "0.2",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second and third reference questions. 3. The question is covered by the fourth and fifth reference questions. 4. The question is not covered by any reference question. 5. The question is covered by the fourth and fifth reference questions. 6. The question is not covered by any reference question. 7. The question is covered by the third reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is covered by the first predicted question. 3. The question is covered by the first predicted question. 4. The question is covered by the first predicted question. 5. The question is covered by the first predicted question.', 'ques_score': {'ref_in_pred': 1, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Reverse image search identifies the photo as a still from the 2022 French film \"Athena\". 2. The image is discussed in Source 13. 3. None of the provided news sources about French protests report or depict protesters commandeering and driving a police van in this manner. 4. The image does not show real French protesters seizing a police vehicle.\\n[REF_FACT]: 1. The image is a still shot from the movie Athena.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first predicted fact is covered by the only fact in the reference fact set.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The reference fact is covered by the first predicted fact.', 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 2; (PRED_3,REF_3);(PRED_8,REF_3)\\n[PRED in REF Exp]: 1. The third fact in the predicted evidence supports the third fact in the reference evidence, stating the image is from the movie Athena and not the riots. 2. The eighth fact in the predicted evidence supports the third fact in the reference evidence, stating the image is from the movie Athena and not the riots.\\n[REF in PRED]: 1; (REF_2,PRED_5)\\n[REF in PRED Exp]: 1. The second fact in the reference evidence is supported by the fifth fact in the predicted evidence, indicating that reports don't confirm protesters seizing vehicles.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_3', 'REF_3'], 'score': '10'}, {'info': ['PRED_8', 'REF_3'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_2', 'PRED_5'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 2, 'detailed_ref_in_pred': '(REF_2,PRED_5)', 'detailed_pred_in_ref': '(PRED_3,REF_3);(PRED_8,REF_3)'}}"
        ],
        [
         "12",
         "1.0",
         "0.75",
         "1",
         "0.6666666666666661",
         "{'ques_feedback': '[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is not covered by any reference question. 3. The question is covered by the third reference question. 4. The question is covered by the third reference question. 5. The question is covered by the third reference question. 6. The question is covered by the third reference question. 7. The question is covered by the fourth reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 4\\n[REF in PRED Exp]: 1. The question is not covered by the predicted questions. 2. The question is not covered by the predicted questions. 3. The question is covered by the third predicted question. 4. The question is covered by the seventh predicted question.', 'ques_score': {'ref_in_pred': 4, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Sources show that Ahmedabad had licensed telephone exchanges from 1881, long before Sabarmati Ashram was founded around 1915, so telephones were present in the city decades earlier. However, none of the sources provide specific information on where exactly the very first telephone in Gujarat or Ahmedabad was installed, nor do they explicitly rule out Sabarmati Ashram. Because the precise location of the first telephone in Gujarat is not documented in the provided material, the claim cannot be definitively refuted or supported and remains without enough evidence.\\n[REF]: QA pairs successfully refute the claim. The first telephone in Gujarat was installed in Ahmedabad, near the Panchkuva Gate, on 17 July 1897, not at Sabarmati Ashram, which was established in 1915 by Mahatma Gandhi upon his return from South Africa.\\n[PRED_FACT]: 1. Ahmedabad had licensed telephone exchanges from 1881. 2. Sabarmati Ashram was founded around 1915. 3. Telephones were present in Ahmedabad decades before the founding of Sabarmati Ashram. 4. The sources do not provide specific information on where the first telephone in Gujarat/Ahmedabad was installed. 5. The sources do not explicitly rule out Sabarmati Ashram. 6. The claim cannot be definitively refuted or supported.\\n[REF_FACT]: 1. The first telephone in Gujarat was installed in Ahmedabad, near the Panchkuva Gate, on 17 July 1897. 2. Sabarmati Ashram was established in 1915. 3. The claim is refuted.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The second predicted fact is covered by the second reference fact.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The first reference fact provides more specific information related to the first predicted fact. 2. The second reference fact is covered by the second predicted fact. 3. The third reference fact is related to the sixth predicted fact.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_7,REF_4)\\n[PRED in REF Exp]: 1. The seventh fact in the predicted evidence claims Sabarmati Ashram was established after May 1915, which aligns with the fourth fact in the reference evidence. 2. The fact is refuted by the first fact in the reference set. 3. The fact is refuted by the second fact in the reference set. 4. The fact is refuted by the third fact in the reference set. 5. The fact is supported by the first fact in the reference evidence. 6. The fact is supported by the first fact in the reference evidence. 7. The fact is supported by the fourth fact in the reference evidence. 8. The fact is refuted by the third fact in the reference set. 9. The fact is refuted by the first fact in the reference set. 10. The fact is supported by the fourth fact in the reference evidence.\\n[REF in PRED]: 3; (REF_3,PRED_3);(REF_4,PRED_7);(REF_1,PRED_9)\\n[REF in PRED Exp]: 1. The third fact in the reference evidence is supported by the third fact in the predicted evidence. 2. The fourth fact in the reference evidence is supported by the seventh fact in the predicted evidence. 3. The first fact in the reference evidence is supported by the ninth fact in the predicted evidence. 4. No related facts can be found in the predicted evidence set. 5. No related facts can be found in the predicted evidence set. 6. No related facts can be found in the predicted evidence set. 7. No related facts can be found in the predicted evidence set. 8. No related facts can be found in the predicted evidence set. 9. No related facts can be found in the predicted evidence set. 10. No related facts can be found in the predicted evidence set.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_7', 'REF_4'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_3', 'PRED_3'], 'score': '10'}, {'info': ['REF_4', 'PRED_7'], 'score': '10'}, {'info': ['REF_1', 'PRED_9'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 3, 'pred_in_ref': 1, 'detailed_ref_in_pred': '(REF_3,PRED_3);(REF_4,PRED_7);(REF_1,PRED_9)', 'detailed_pred_in_ref': '(PRED_7,REF_4)'}}"
        ],
        [
         "13",
         "1.0",
         "0.0",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. No predicted question is fully covered by any of the reference questions.\\n[REF in PRED]: 4\\n[REF in PRED Exp]: 1. The question is not covered by any of the predicted questions. 2. The question is covered by the fifth and eighth predicted question. 3. The question is covered by the second and eighth predicted questions. 4. The question is covered by the ninth predicted question.', 'ques_score': {'ref_in_pred': 4, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED_FACT]: 1. The British government owned and expanded telephone infrastructure in India for administrative and military purposes. 2. There is no mention of a special, expensive line installed specifically for Gandhi. 3. There is no mention of spending 'lakhs' on such a connection. 4. The sources do not directly address the specific line or phone shown in the image. 5. The sources do not explicitly rule out any ad hoc arrangements for Gandhi’s communication. 6. There is not enough evidence to determine the claim’s truthfulness.\\n[REF_FACT]: 1. Gandhi was not in India at the time the phones were installed in Ahmedabad. 2. The phones were installed in Ahmedabad by The Bombay Telephone Company.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by nor similar to any reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any reference fact. 2. The fact is not covered by nor similar to any reference fact.\", 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence discusses telephone communication with Gandhi and historical context, while the reference evidence focuses on the establishment of telephone services in India and Gandhi's location in 1941. There is no overlap in content. 2. The predicted evidence does not mention the Oriental Telephone Company. 3. The predicted evidence does not mention the Bombay Telephone Company or its services in Ahmedabad. 4. The predicted evidence does not mention Gandhi’s return to India in 1915.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence only provides a photo and historical context on the beginning of telephone services in India and does not support any of the predictions about Gandhi's telephone communication. 2. The reference evidence provides no information related to a special telephone line for Gandhi. 3. The reference evidence does not support or refute any claims about spending 'lakhs' of rupees. 4. The reference evidence does not contain information on telephone infrastructure use by Gandhi.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "14",
         "1.0",
         "0.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first and second reference questions, as they both ask about the location of the image. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is covered by the first and second reference questions, as they both ask about the location of the image. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the first predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED]: Source 1 explains that the protest image with the banner 'They are not dangerous, they are in danger! Refugees welcome' is from a 2015 solidarity march in Brussels, Belgium, not from France in 2016, while the fiery image does show recent riots in France. Since the claim asserts that both images depict events in France (a pro‑refugee protest in 2016 and later riots), and one of these attributions is factually wrong, the overall claim is refuted.\\n[REF]: The claim is successfully refuted by proving that CLAIM_IMG_1 was taken in Brussels in 2015.\\n[PRED_FACT]: 1. The protest image with the banner 'They are not dangerous, they are in danger! Refugees welcome' is from a 2015 solidarity march in Brussels, Belgium. 2. The fiery image shows recent riots in France. 3. The claim asserts that both images depict events in France. 4. One of the attributions is factually wrong.\\n[REF_FACT]: 1. CLAIM_IMG_1 was taken in Brussels in 2015.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact is covered by the reference fact.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The fact is covered by the first fact in the predicted fact set.\", 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_1,REF_2)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence aligns with the second fact in the reference evidence, both stating the location and year of the march photo.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_2'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_1,REF_2)'}}"
        ],
        [
         "15",
         "1.0",
         "0.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first reference question. 3. The question is covered by the first reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is covered by the first reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is covered by the first reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first and tenth predicted question. 2. The question is not covered by any predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED_FACT]: 1. The first image is a modern re-created or digital artwork. 2. The first image is not an original painting by Raja Ravi Varma. 3. No art references list this portrait among Ravi Varma’s works.\\n[REF_FACT]: 1. The 0th image does not show Raja Ravi Varma's original painting. 2. The 0th image is a recreation by a studio.\\n[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The fact is covered by the second fact in the reference fact set. 2. The fact is consistent with the first fact in the reference fact set. 3. This fact provides further detail supporting the reference facts.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The fact is covered by the first fact in the predicted fact set. 2. The fact is covered by the second fact in the predicted fact set.\", 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 2; (PRED_1,REF_1);(PRED_2,REF_2)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence supports the first fact in the reference evidence, stating the image is a recreation, not an original painting. 2. The second fact in the predicted evidence supports the second fact in the reference evidence, mentioning a comparison of the original painting and the recreation.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence. 2. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_2', 'REF_2'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 2, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_2,REF_2)'}}"
        ],
        [
         "16",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first and fourth reference questions. 3. The question is covered by the second reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is covered by the third reference question.\\n[REF in PRED]: 4\\n[REF in PRED Exp]: 1. The question is covered by the fourth predicted question. 2. The question is covered by the third predicted question. 3. The question is covered by the third predicted question. 4. The question is covered by the first and fourth predicted questions.', 'ques_score': {'ref_in_pred': 4, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED]: The sign clearly labels the ‘New World Order’ line as a joke with the words “Just kidding” and then provides a mundane operational reason for being card-only (saving time on counting cash). Independent coverage shows Nando’s and many other UK businesses moved toward card-only payments due to practical and pandemic-related factors, not participation in any ‘New World Order’ scheme. There is no evidence that Nando’s contradicts the joking nature of the phrase, so the assertion that “this is not a joke” is not supported and is best classified as refuted.\\n[REF]: The claim is successfully refuted with evidence directly from Nando's website that indicates they accept both cash and cards.\\n[PRED_FACT]: 1. The sign labels the ‘New World Order’ line as a joke with the words “Just kidding”. 2. The sign provides a mundane operational reason for being card-only (saving time on counting cash). 3. Independent coverage shows Nando’s and many other UK businesses moved toward card-only payments due to practical and pandemic-related factors. 4. There is no evidence that Nando’s contradicts the joking nature of the phrase.\\n[REF_FACT]: 1. Nando's website indicates they accept both cash and cards.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by nor similar to any reference fact. 3. The fact is not covered by nor similar to any reference fact. 4. The fact is not covered by nor similar to any reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by the predicted fact set.\", 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence contradicts the fourth reference fact, which claims Nando’s accepts both cash and card. 2. The predicted evidence contradicts the fourth reference fact, which claims Nando’s accepts both cash and card. 3. The predicted evidence does not mention the source of the image. 4. The predicted evidence contradicts the fourth reference fact, which claims Nando’s accepts both cash and card.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence states “No answer was found regarding whether Nando's in the UK accept payment by cash”, which contradicts several facts in the predicted evidence that discuss card-only policies. 2. The reference evidence states “No answer was found regarding the types of payment Nando's accepts in stores in the UK”, which contradicts several facts in the predicted evidence that discuss card-only policies. 3. The reference evidence states “No answer was found regarding the source of [IMG_1]”, while the predicted evidence provides details about the sign’s text. 4. The reference evidence states “Nandos in the UK currently accepts both cash and card payments”, which directly contradicts multiple claims in the predicted evidence.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "17",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is not covered by nor similar to any reference question. 2. The question is not covered by nor similar to any reference question. 3. The question is covered by the second reference question. 4. The question is not covered by nor similar to any reference question. 5. The question is not covered by nor similar to any reference question. 6. The question is not covered by nor similar to any reference question. 7. The question is not covered by nor similar to any reference question. 8. The question is not covered by nor similar to any reference question. 9. The question is not covered by nor similar to any reference question. 10. The question is not covered by nor similar to any reference question.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is covered by the third predicted question. 3. The question is covered by the third predicted question.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: The same image has been traced to reports identifying it as a block of animal intestines/offal that fell from a meat truck in Russia, not human remains. Multiple independent news reports on how Russia handles its war dead describe storage in body bags, refrigerated trains, zinc coffins, or a converted meat‑packing plant, and none mention compressing soldiers’ bodies into ‘meat cubes.’ Thus the claim that the image shows Russia transporting dead soldiers in ‘meat cubes’ is contradicted by the best available evidence.\\n[REF]: The claim is refuted by QA pairs. Based on the evidence ,the image shows frozen dog food for the animal shelter.\\n[PRED_FACT]: 1. The image shows a block of animal intestines/offal that fell from a meat truck in Russia, not human remains. 2. Reports on how Russia handles its war dead describe storage in body bags, refrigerated trains, zinc coffins, or a converted meat‑packing plant. 3. None of the reports mention compressing soldiers’ bodies into ‘meat cubes.’ 4. The claim that the image shows Russia transporting dead soldiers in ‘meat cubes’ is contradicted by the best available evidence.\\n[REF_FACT]: 1. The image shows frozen dog food for the animal shelter.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact. 2. The fact is not covered by the reference fact. 3. The fact is not covered by the reference fact. 4. The fact is not covered by the reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence does not align with any fact in the reference evidence. 2. The second fact in the predicted evidence does not align with any fact in the reference evidence. 3. The third fact in the predicted evidence does not align with any fact in the reference evidence. 4. The fourth fact in the predicted evidence does not align with any fact in the reference evidence. 5. The fifth fact in the predicted evidence does not align with any fact in the reference evidence. 6. The sixth fact in the predicted evidence does not align with any fact in the reference evidence. 7. The seventh fact in the predicted evidence does not align with any fact in the reference evidence. 8. The eighth fact in the predicted evidence does not align with any fact in the reference evidence. 9. The ninth fact in the predicted evidence does not align with any fact in the reference evidence. 10. The tenth fact in the predicted evidence does not align with any fact in the reference evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The first fact in the reference evidence is not supported by any fact in the predicted evidence. 2. The second fact in the reference evidence is not supported by any fact in the predicted evidence. 3. The third fact in the reference evidence is not supported by any fact in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "18",
         "0.5",
         "0.25",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is not covered by any reference question. 3. This question is covered by the second and third reference questions. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is covered by the first predicted question. 3. The question is covered by the first predicted question. 4. The question is not covered by any predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: News reports identify the main accused in the Manipur viral video case as Huirem Herodas/Heradash Meitei, seen in the video wearing a green T‑shirt. The provided image sources show that the photo used in the claim actually depicts RSS volunteers at a rally in Gauhati in 2018, not men named or described as accused in the Manipur case. No source links the specific two uniformed men in the photo to the arrests in the case. Therefore, the assertion that this photo shows men accused in the Manipur viral video case is refuted.\\n[REF]: QA pairs neither support nor refute the claim. The evidence is insufficient and does not rule out the possibility of a connection between the two men in the image and the Manipur violence. The men in the photo are not identified, nor are images of the accused provided.\\n[PRED_FACT]: 1. News reports identify the main accused in the Manipur viral video case as Huirem Herodas/Heradash Meitei. 2. The photo depicts RSS volunteers at a rally in Gauhati in 2018. 3. The photo does not depict men named or described as accused in the Manipur case. 4. No source links the men in the photo to the arrests in the case.\\n[REF_FACT]: 1. QA pairs neither support nor refute the claim. 2. The evidence is insufficient. 3. The evidence does not rule out a connection between the men in the image and the Manipur violence. 4. The men in the photo are not identified. 5. Images of the accused are not provided.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the evidence is insufficient (REF fact 2) covers the idea that no source links the men to the arrests (PRED fact 4).\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by any predicted fact. 2. The fact is not covered by any predicted fact. 3. The fact is not covered by any predicted fact. 4. The fact is not covered by any predicted fact. 5. The fact is not covered by any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 2; (PRED_1,REF_3);(PRED_3,REF_3)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence and the third fact in the reference evidence both mention Huirem Herodas. 2. The third fact in the predicted evidence and the third fact in the reference evidence both mention Huirem Herodas. 3. The rest of the predicted facts contradict the reference evidence or are not supported by it.\\n[REF in PRED]: 1; (REF_3,PRED_1)\\n[REF in PRED Exp]: 1. The third fact in the reference evidence is supported by the first fact in the predicted evidence. 2. The rest of the reference facts are not found or contradicted by the predicted evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_3'], 'score': '10'}, {'info': ['PRED_3', 'REF_3'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_3', 'PRED_1'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 2, 'detailed_ref_in_pred': '(REF_3,PRED_1)', 'detailed_pred_in_ref': '(PRED_1,REF_3);(PRED_3,REF_3)'}}"
        ],
        [
         "19",
         "0.6666666666666661",
         "0.0",
         "0",
         "0.5",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. This question is not covered by any reference question. 2. The question is covered by the third reference question. 3. This question is not covered by any reference question. 4. This question is covered by the third reference question. 5. This question is not covered by any reference question. 6. This question is not covered by any reference question. 7. This question is not covered by any reference question. 8. This question is not covered by any reference question. 9. This question is not covered by any reference question. 10. This question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. This question is not covered by the predicted question set. 2. This question is not covered by the predicted question set. 3. This question is covered by the third and fourth predicted questions.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Reverse image search links the picture to the 2022 French film “Athena,” described in source 15 as a fictional feature depicting staged riots. The image appears there as a film still, and no news source reports an actual incident where protesters seized and drove a French police van in this manner. Therefore, claiming the image shows real French protesters seizing a police vehicle is false.\\n[REF]: The claim is neither supported nor refuted. The information provided does not identify the image, which is easily learned through using a reverse image search.\\n[PRED_FACT]: 1. Reverse image search links the picture to the 2022 French film “Athena.” 2. “Athena” is a fictional feature depicting staged riots. 3. The image appears in “Athena” as a film still. 4. No news source reports an actual incident where protesters seized and drove a French police van. 5. Claiming the image shows real French protesters seizing a police vehicle is false.\\n[REF_FACT]: 1. The information provided does not identify the image. 2. The image can be identified through a reverse image search.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that a reverse image search can identify the image is consistent with the predicted fact set. 2. The fact is not covered by the predicted fact set. 3. The fact is not covered by the predicted fact set. 4. The fact is not covered by the predicted fact set. 5. The fact is not covered by the predicted fact set.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The fact that the image is not identified by the provided information is covered by the predicted fact that a reverse image search identified it. 2. The fact is not covered by the predicted fact set.', 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence provides extensive details about a film (\"Athena\") and its relation to the image, which is not present in the reference evidence. 2. The reference evidence does not offer information about the film \"Athena\". 3. The reference evidence does not address the specifics of the image content beyond stating it\\'s origin is unknown.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence only states the cause of protests in France in July 2023, which is not mentioned in the predicted evidence. 2. The predicted evidence does not mention the unknown location of the image. 3. The predicted evidence does not mention whether protesters seized a police vehicle.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "20",
         "1.0",
         "0.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. 2. The question is covered by the second reference question. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is covered by the first reference question. 10. The question is covered by the first reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the second predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED_FACT]: 1. Reverse-image-search sources identify the photo as the Ya'an–Kangding Expressway in Sichuan Province, China. 2. The sources provide captions about its construction and location. 3. None of the sources link this image to India or to National Highway 44. 4. India-focused sources describe NH 44’s route but do not match the image. 5. Labeling the image as Jammu National Highway 44 in India is incorrect.\\n[REF_FACT]: 1. The image shows the Weiyuan-Wudu Expressway in Northwest China.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first fact in the predicted fact set is covered by the fact in the reference fact set, as both refer to the image showing an expressway in China.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The fact is covered by the first fact in the predicted fact set, as both refer to the image showing an expressway in China.\", 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence extensively discusses reverse image search results identifying the image as a Chinese expressway, a topic absent in the reference evidence. 2. The reference evidence simply states the image is of a highway in India and another highway in China, lacking the detailed analysis present in the predicted evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence makes a direct claim about the image’s location (India and China) which is contradicted by the predicted evidence’s finding that it is exclusively a Chinese expressway. 2. The predicted evidence does not mention the specific expressway named in the reference evidence (Weiyuan-Wudu Expressway in Gansu Province).', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "21",
         "1.0",
         "0.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second reference question. 3. The question is covered by the first reference question. 4. The question is not covered by any reference question. 5. The question is covered by the second reference question. 6. The question is not covered by any reference question. 7. The question is covered by the first reference question. 8. The question is covered by the first reference question. 9. The question is covered by the second reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the second predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Fact-checks by Snopes and PesaCheck trace the widely shared melted traffic light image to a vehicle crash and fire in Kuwait in 2013, not to extreme heat in Texas. The provided sources document Texas heat melting road asphalt but not traffic signals, and they explicitly note that such viral melting images are frequently misattributed to heat waves. No evidence links this specific photograph to Texas or to melting caused solely by high air temperatures, so the claim is refuted.\\n[REF]: Although the method of disproving the claim is faulty, the claim is refuted by showing that a fire under the traffic light, and not high temperatures, caused the melting.\\n[PRED_FACT]: 1. Snopes and PesaCheck trace the image to a vehicle crash and fire in Kuwait in 2013. 2. The image is not related to extreme heat in Texas. 3. Sources document Texas heat melting road asphalt but not traffic signals. 4. Viral melting images are frequently misattributed to heat waves. 5. No evidence links the photo to Texas or melting caused by high air temperatures.\\n[REF_FACT]: 1. The claim is refuted by a fire under the traffic light. 2. High temperatures did not cause the melting.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the melting was caused by a fire is consistent with the first predicted fact, which states the image is from a vehicle crash and fire.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The fact is covered by the second fact in the predicted fact set. 2. The fact is covered by the fifth fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 2; (PRED_2,REF_2);(PRED_5,REF_2)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence mentions a similar scenario of melted traffic lights due to vehicle fires, aligning with the reference evidence. 2. The fifth fact supports the claim that the melting event was due to a vehicle fire in Kuwait, as stated in the reference evidence. 3. The remaining facts in the predicted evidence discuss details about the origin and context of the image, which are not directly addressed in the reference evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence states no answer could be found regarding traffic lights melting due to heatwaves, contradicting the affirmative statements in the predicted evidence. 2. The reference evidence directly supports the second fact in the predicted evidence but no other predicted facts.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_2', 'REF_2'], 'score': '10'}, {'info': ['PRED_5', 'REF_2'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 2, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_2,REF_2);(PRED_5,REF_2)'}}"
        ],
        [
         "22",
         "1.0",
         "0.5",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second reference question. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is covered by the second reference question. 9. The question is covered by the first reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first and ninth predicted questions. 2. The question is covered by the sixth and eighth predicted questions.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Sources consistently state that US ambassador to Jamaica Nick Perry is married to his wife Joyce (née Mahabeer). Image-based fact-checks identify the bearded person in a dress in the viral photo as Austrian drag performer Conchita Wurst and note that the people in the picture are often falsely claimed to be political leaders or their spouses. No source links the image to Nick Perry, and the description of his spouse does not match the individuals shown. Therefore, the claim that the photo shows US ambassador Nickolas Perry with his spouse is refuted.\\n[REF]: The claim is refuted by proving that the person in the dress in the photograph is the singer Conchita Wurst and that Nickolas Perry does not look like the man in the image.\\n[PRED_FACT]: 1. Nick Perry is married to Joyce (née Mahabeer). 2. The bearded person in the dress in the viral photo is Austrian drag performer Conchita Wurst. 3. The people in the picture are often falsely claimed to be political leaders or their spouses. 4. No source links the image to Nick Perry. 5. The description of his spouse does not match the individuals shown.\\n[REF_FACT]: 1. The person in the dress in the photograph is the singer Conchita Wurst. 2. Nickolas Perry does not look like the man in the image.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first reference fact is covered by the second predicted fact.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The first reference fact is similar to the second predicted fact. 2. The second reference fact is covered by the fourth and fifth predicted fact.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence contains information not found in the reference evidence. 2. The predicted evidence contains information not found in the reference evidence.\\n[REF in PRED]: 1; (REF_2,PRED_6)\\n[REF in PRED Exp]: 1. The second fact in the reference evidence aligns with the sixth fact in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': [{'info': ['REF_2', 'PRED_6'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 0, 'detailed_ref_in_pred': '(REF_2,PRED_6)', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "23",
         "1.0",
         "0.5",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 0\\n[PRED in REF Exp]: None of the predicted questions are covered by the reference questions.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is covered by the fourth predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Sources show Anon Numpa’s widely reported arrest in connection with pro‑democracy protests occurred in August 2020, and similar images are tied to 2020–2021 protest crackdowns, not July 2023. The provided material does not confirm that the person in the photo is Anon Numpa or that the scene took place in July 2023, so the specific claim about identity and date is inaccurate.\\n[REF]: The claim is successfully refuted. The photo is not from 2023, but from the 2020 arrest of Anon Numpa.\\n[PRED_FACT]: 1. Anon Numpa’s arrest occurred in August 2020. 2. Similar images are tied to 2020–2021 protest crackdowns. 3. The provided material does not confirm that the person in the photo is Anon Numpa. 4. The provided material does not confirm that the scene took place in July 2023.\\n[REF_FACT]: 1. The photo is not from 2023. 2. The photo is from the 2020 arrest of Anon Numpa.\\n[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The fact is not covered by any reference fact. 2. The fact is covered by the second fact in the reference fact set. 3. The fact is not covered by any reference fact. 4. The fact is covered by the first fact in the reference fact set.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The fact is covered by the first and fourth facts in the predicted fact set. 2. The fact is covered by the first and second facts in the predicted fact set.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 2; (PRED_1,REF_2);(PRED_4,REF_2)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence mentions Anon Numpa's arrest, which is supported by the second fact in the reference evidence mentioning his arrest with Panupong Jadnok. 2. The fourth fact mentions Thai police detaining two men, which is similarly described in the second fact of the reference evidence.\\n[REF in PRED]: 2; (REF_2,PRED_1);(REF_2,PRED_4)\\n[REF in PRED Exp]: 1. The second fact in the reference evidence supports the first fact in the predicted evidence mentioning Anon Numpa's arrest. 2. The second fact in the reference evidence supports the fourth fact in the predicted evidence mentioning the arrest of Anon Numpa and Panupong Jadnok.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_2'], 'score': '10'}, {'info': ['PRED_4', 'REF_2'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_2', 'PRED_1'], 'score': '10'}, {'info': ['REF_2', 'PRED_4'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '(REF_2,PRED_1);(REF_2,PRED_4)', 'detailed_pred_in_ref': '(PRED_1,REF_2);(PRED_4,REF_2)'}}"
        ],
        [
         "24",
         "0.833333333333333",
         "0.33333333333333304",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 4\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second and third reference questions. 3. The question is covered by the third reference question. 4. The question is covered by the sixth reference question. 5. The question is covered by the fifth reference question. 6. The question is covered by the sixth reference question. 7. The question is covered by the third and fourth reference questions. 8. The question is not covered by any reference question. 9. The question is covered by the sixth reference question. 10. The question is covered by the sixth reference question.\\n[REF in PRED]: 5\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is not covered by any predicted question. 3. The question is partially covered by the third and seventh predicted questions. 4. The question is partially covered by the fourth and seventh predicted questions. 5. The question is covered by the fifth predicted question. 6. The question is covered by the fourth and sixth predicted questions.', 'ques_score': {'ref_in_pred': 5, 'pred_in_ref': 4, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. The image shows a Ram-branded pickup truck. 2. Ram is an established U.S. truck brand under Stellantis. 3. The Ram name and products are not linked to the Hindu deity Lord Rama. 4. No source reports any American automaker launching a new vehicle explicitly named after Lord Rama. 5. The claim confuses the Ram brand name with the Hindu deity.\\n[REF_FACT]: 1. The RAM logo has been in use since 1932. 2. The RAM logo was modeled on the idea of a charging ram animal.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the RAM logo has been in use since 1932 supports the statement that Ram is an established brand.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The fact that the logo was modeled on a charging ram animal provides further detail on the brand and is consistent with the predicted fact that the Ram name is not linked to the Hindu deity. 2. The fact is similar to the first fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 4; (PRED_1,REF_1);(PRED_2,REF_6);(PRED_7,REF_6);(PRED_9,REF_6)\\n[PRED in REF Exp]: 1. The first fact is supported by the first fact in the reference evidence. 2. The second fact is supported by the sixth fact in the reference evidence. 3. The seventh fact is supported by the sixth fact in the reference evidence. 4. The ninth fact is supported by the sixth fact in the reference evidence.\\n[REF in PRED]: 2; (REF_5,PRED_5);(REF_6,PRED_6)\\n[REF in PRED Exp]: 1. The fifth fact is supported by the fifth fact in the predicted evidence. 2. The sixth fact is supported by the sixth fact in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_2', 'REF_6'], 'score': '10'}, {'info': ['PRED_7', 'REF_6'], 'score': '10'}, {'info': ['PRED_9', 'REF_6'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_5', 'PRED_5'], 'score': '10'}, {'info': ['REF_6', 'PRED_6'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 2, 'pred_in_ref': 4, 'detailed_ref_in_pred': '(REF_5,PRED_5);(REF_6,PRED_6)', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_2,REF_6);(PRED_7,REF_6);(PRED_9,REF_6)'}}"
        ],
        [
         "25",
         "1.0",
         "0.0",
         "1",
         "0.33333333333333304",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second reference question. 3. The question is not covered by any reference question. 4. The question is covered by the first reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the fourth predicted question. 2. The question is covered by the second predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Reports describe an official aerial handout photo released by the Greek coast guard showing the trawler upright with people densely packed on deck and most not wearing life jackets. 2. The claim image shows a different-looking vessel at sea level, already listing, with many people in the water wearing life jackets. 3. None of the sources reproduce or describe an image matching the claim photo or link such an image to the June 2023 Greek shipwreck. 4. The claim that the photo shows the trawler that went down off Greece is refuted.\\n[REF_FACT]: 1. The claim that the photo shows the fishing trawler that went down off Greece in June 2023 is false. 2. The image is related to a different event. 3. The image was originally published in 2016, not in 2023.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first predicted fact aligns with the first reference fact, stating the claim is false. 2. The fact is not covered by nor similar to any reference fact. 3. The fact is not covered by nor similar to any reference fact. 4. The fact is similar to the first reference fact.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The fact is covered by the first and fourth predicted facts. 2. The fact is covered by the third predicted fact. 3. The fact is covered by the third predicted fact.', 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence discusses a shipwreck off Greece in June 2023 and details surrounding an image related to the event, while the reference evidence states the image was taken off the coast of Libya and published in 2016. These are unrelated events and locations. 2. The predicted evidence details surrounding a shipwreck off Greece in June 2023 and details surrounding an image related to the event, while the reference evidence states the image was published in May 2016. These are unrelated events and dates.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant information regarding the location of the image being off the coast of Libya is present in the predicted evidence. 2. No relevant information regarding the publication date of May 25, 2016 is present in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "26",
         "0.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 0\\n[PRED in REF Exp]: None of the predicted questions are covered by the reference questions. The predicted questions concern a migrant boat disaster off the coast of Greece, while the reference questions concern PM Modi and a religious ceremony.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: None of the reference questions are covered by the predicted questions. The reference questions concern a different event and topic from the predicted questions.', 'ques_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Reports describe an official aerial handout photo released by the Greek coast guard showing the trawler upright with people densely packed on deck and most not wearing life jackets. 2. The claim image shows a different-looking vessel at sea level, already listing, with many people in the water wearing life jackets. 3. None of the sources reproduce or describe an image matching the claim photo or link such an image to the June 2023 Greek shipwreck. 4. The claim that the photo shows the trawler that went down off Greece is refuted.\\n[REF_FACT]: 1. The claim is refuted by providing a video that shows the full movement of PM Modi. 2. The claim image is just a still shot from his full movement in a circle.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set. 4. The fact is not covered by the reference fact set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence does not contain information about Hindu deities or disrespectful behavior. 2. The predicted evidence does not mention PM Modi or a visit to a temple. 3. The predicted evidence does not mention PM Modi performing a parikrama. 4. The predicted evidence does not define or discuss the parikrama ritual. 5. The predicted evidence does not discuss PM Modi's movement or position in relation to a deity.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence discusses religious respect and rituals, which are not covered in the predicted evidence. 2. The reference evidence focuses on a specific event involving PM Modi, not addressed in the predicted evidence. 3. The reference evidence’s detail about Modi's action is absent in the predicted evidence. 4. The predicted evidence does not provide context on Hindu rituals. 5. The predicted evidence makes no reference to the events described in the reference evidence.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "27",
         "1.0",
         "0.33333333333333304",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first reference question. 3. The question is not covered by any reference question. 4. The question is covered by the third reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is covered by the first reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is covered by the eighth predicted question. 2. The question is not covered by any predicted question. 3. The question is covered by the tenth predicted question.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED]: The sources explain what Silver Alerts are and give examples, but none mention a missing person named Jackson Simmons, a dog named Cami, or a Silver Alert that matches the provided images. There is also no evidence directly disproving that such an alert ever existed. Because the specific case is neither corroborated nor contradicted by the available material, the claim cannot be verified or refuted and is best classified as lacking sufficient evidence.\\n[REF]: The claim that drinking lemon juice and hot water cures cancer is unsupported by scientific evidence. While lemons have health benefits, there's no proof they can cure cancer.\\n[PRED_FACT]: 1. The sources explain what Silver Alerts are and give examples. 2. None of the sources mention a missing person named Jackson Simmons. 3. None of the sources mention a dog named Cami. 4. None of the sources mention a Silver Alert that matches the provided images. 5. There is no evidence directly disproving that such an alert ever existed. 6. The specific case is neither corroborated nor contradicted by the available material. 7. The claim cannot be verified or refuted. 8. The claim is best classified as lacking sufficient evidence.\\n[REF_FACT]: 1. The claim that drinking lemon juice and hot water cures cancer is unsupported by scientific evidence. 2. Lemons have health benefits. 3. There is no proof lemons can cure cancer.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. No overlap in content. 2. No overlap in content. 3. No overlap in content. 4. No overlap in content. 5. No overlap in content. 6. No overlap in content. 7. No overlap in content. 8. No overlap in content.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. No overlap in content. 2. No overlap in content. 3. No overlap in content.\", 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_10,REF_3)\\n[PRED in REF Exp]: 1. The predicted evidence does not mention a specific alert system, while the reference mentions Colorado uses \"Missing Senior Citizen Alert\" instead of \"silver alert\". 2. The predicted evidence does not mention any bait-and-switch scams. 3. The predicted evidence does not mention the post’s edit history.\\n[REF in PRED]: 1; (REF_3,PRED_10)\\n[REF in PRED Exp]: 1. The reference evidence confirms that the original post discussed \"Jackson Simmons\" and \"Cami\" before being altered, supporting the predicted evidence\\'s statement that no such information can be found currently. 2. The reference evidence does not provide information about GMC Sierra or alert systems. 3. The reference evidence does not provide information about the images of dogs or men.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_10', 'REF_3'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_3', 'PRED_10'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '(REF_3,PRED_10)', 'detailed_pred_in_ref': '(PRED_10,REF_3)'}}"
        ],
        [
         "28",
         "1.0",
         "0.2",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the second reference question.\\n[REF in PRED]: 5\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is covered by the first predicted question. 3. The question is covered by the second predicted question. 4. The question is covered by the fourth predicted question. 5. The question is covered by the fifth predicted question.', 'ques_score': {'ref_in_pred': 5, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED]: Reverse image search shows the highway in the photo is a Chinese expressway (such as the Wenchuan–Ma'erkang or Taihang Mountain expressway), not India’s NH‑44. Indian sources confirm NH‑44 runs from Srinagar to Kanyakumari entirely within India, and a Punjabi fact-check explicitly notes that this viral image has been wrongly shared as a Jammu–Srinagar/NH‑44 highway. Therefore, the specific claim that this picture shows NH‑44 is false, even though NH‑44 itself does connect Srinagar and Kanyakumari.\\n[REF]: The claim is successfully refuted by proving that the image is from Northwest China's Gansu Province, not India.\\n[PRED_FACT]: 1. Reverse image search shows the highway in the photo is a Chinese expressway. 2. The highway in the photo is not India’s NH‑44. 3. NH‑44 runs from Srinagar to Kanyakumari entirely within India. 4. The image has been wrongly shared as a Jammu–Srinagar/NH‑44 highway. 5. The specific claim that this picture shows NH‑44 is false.\\n[REF_FACT]: 1. The image is from Northwest China's Gansu Province. 2. The image is not from India.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first fact in the predicted fact set is similar to the first fact in the reference fact set.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The first fact in the reference fact set is covered by the first and second facts in the predicted fact set. 2. The second fact in the reference fact set is covered by the second fact in the predicted fact set.\", 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 2; (PRED_2,REF_3);(PRED_6,REF_2)\\n[PRED in REF Exp]: 1. The claim about the highway being in China is supported by the third reference fact, which identifies the road as being in Northwest China's Gansu Province. 2. The fact that sources identify the image as a Chinese expressway is supported by the second fact in the reference set. 3. The facts about NH-44 being in India (facts 4, 7, 9) are not directly mentioned in the reference evidence. 4. The claim about the looping viaduct is not addressed in the reference evidence. 5. The conclusion that the image contradicts the claim is consistent with the reference evidence’s focus on a Chinese expressway.\\n[REF in PRED]: 1; (REF_3,PRED_2)\\n[REF in PRED Exp]: 1. The third reference fact directly supports the predicted fact stating the road is the Weiyuan-Wudu Expressway in Northwest China's Gansu Province. 2. The first and second reference facts are not supported. 3. The fourth and fifth reference facts do not support any facts in the prediction.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_2', 'REF_3'], 'score': '10'}, {'info': ['PRED_6', 'REF_2'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_3', 'PRED_2'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 2, 'detailed_ref_in_pred': '(REF_3,PRED_2)', 'detailed_pred_in_ref': '(PRED_2,REF_3);(PRED_6,REF_2)'}}"
        ],
        [
         "29",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. The rest of the predicted questions are not covered by the reference question set.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The question is covered by the fifth predicted question.', 'ques_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Police Scotland have stated that no children are missing from the Falkirk area. 2. Facebook appeals about a kidnapped girl in Falkirk are fake phishing scams. 3. The image used in the claim is from a BBC report about stolen dachshunds in Thirsk, North Yorkshire. 4. The image is not linked to any missing child named Sofia or to Falkirk.\\n[REF_FACT]: 1. The dogs were stolen from North Yorkshire, England. 2. The source identifies the child as their owner, Ruby.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the dogs were stolen from North Yorkshire is consistent with the predicted fact that the image is from Thirsk, North Yorkshire. 2. The predicted facts do not mention Ruby. 3. The predicted facts do not mention Ruby. 4. The predicted facts do not mention Ruby.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by the predicted fact set.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_5,REF_1)\\n[PRED in REF Exp]: 1. The fifth fact in the predicted evidence aligns with the first fact in the reference evidence, both describing the image and its connection to stolen dachshunds.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_5', 'REF_1'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_5,REF_1)'}}"
        ],
        [
         "30",
         "0.2",
         "0.2",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first predicted question is covered by the first reference question. The remaining questions are not covered by any of the reference questions.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The first reference question is covered by the first predicted question. 2. The question is not covered by any predicted question. 3. The question is not covered by any predicted question. 4. The question is not covered by any predicted question. 5. The question is not covered by any predicted question.', 'ques_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED]: Fact-checking in Source 1 shows the claim that Kuki militants laid down arms after meeting Rahul Gandhi comes from a parody PTI account and is false. The image used with the claim is traced in Sources 13 and 14 to a July 2022 police arrest of two Kuki National Army-India cadres for extortion, unrelated to Rahul Gandhi’s 2023 visit. Reports on his Manipur trip (Sources 3, 5, 6) make no mention of any militants surrendering because of him. The men in the photo were arrested, not voluntarily surrendering after a meeting with Rahul Gandhi.\\n[REF]: The claim is neither supported nor refuted. The only information provided is that the image shows Kuki militants photographed in 2022 in Manipur where Gandhi was to appear. The claim date is missing, so it is difficult to determine whether the two events are related.\\n[PRED_FACT]: 1. The claim that Kuki militants laid down arms after meeting Rahul Gandhi comes from a parody PTI account and is false. 2. The image used with the claim is traced to a July 2022 police arrest of two Kuki National Army-India cadres for extortion. 3. The image is unrelated to Rahul Gandhi’s 2023 visit. 4. Reports on Rahul Gandhi’s Manipur trip make no mention of any militants surrendering. 5. The men in the photo were arrested, not voluntarily surrendering.\\n[REF_FACT]: 1. The claim is neither supported nor refuted. 2. The image shows Kuki militants photographed in 2022 in Manipur where Gandhi was to appear. 3. The claim date is missing, making it difficult to determine if the events are related.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The predicted fact about the image showing Kuki militants in Manipur is covered by the second reference fact. 2. The other facts provide additional details not present in the reference.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The reference's overall stance on the claim's support or refutation is not explicitly stated in the predicted facts. 2. The reference's point about the missing claim date is not included in the predicted facts. 3. The reference fact about the image location and date isn't expanded upon in the prediction.\", 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_4,REF_4)\\n[PRED in REF Exp]: 1. The fourth predicted fact aligns with the fourth fact in the reference evidence, both referencing a news article about Kuki insurgents and an image match.\\n[REF in PRED]: 1; (REF_4,PRED_5)\\n[REF in PRED Exp]: 1. The fourth fact in the reference evidence is supported by the fifth predicted fact, as both mention the news article and arrests of Kuki National Army-India (KNA-I) cadres for extortion.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_4', 'REF_4'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_4', 'PRED_5'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '(REF_4,PRED_5)', 'detailed_pred_in_ref': '(PRED_4,REF_4)'}}"
        ],
        [
         "31",
         "1.0",
         "0.6000000000000001",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is not covered by any reference question. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is similar to the fourth and fifth reference questions. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is covered by the second reference question.\\n[REF in PRED]: 5\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is not covered by any predicted question. 3. The question is not covered by any predicted question. 4. The question is covered by the seventh predicted question. 5. The question is covered by the seventh predicted question.', 'ques_score': {'ref_in_pred': 5, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. The NOAA map matching the image is routinely miscaptioned as showing radiation from Fukushima. 2. The NOAA map is actually a model of tsunami wave heights from the 2011 earthquake. 3. Fact-checkers have labeled the radiation interpretation a hoax. 4. The claim that the photo shows the spread path of radioactive materials from the Fukushima nuclear plant estimated by NOAA is false.\\n[REF_FACT]: 1. The NOAA image is of the effects and reach of a 2011 tsunami in the area.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the NOAA image is of a tsunami is covered by the reference fact.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The reference fact is covered by the first and second predicted facts.', 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 5; (PRED_1,REF_5);(PRED_7,REF_5);(PRED_10,REF_5)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence relates to the fifth fact in the reference evidence, which describes the image as showing model amplitudes calculated with the MOST forecast model. 2. The seventh fact in the predicted evidence describes the visual appearance of the map, which is also detailed in the fifth fact in the reference evidence. 3. The tenth fact in the predicted evidence explains the purpose of the map, aligning with the information in the fifth fact from the reference evidence.\\n[REF in PRED]: 3; (REF_2,PRED_1);(REF_4,PRED_1);(REF_5,PRED_10)\\n[REF in PRED Exp]: 1. The second fact in the reference evidence provides details about NOAA, which is relevant to the first fact in the predicted evidence, discussing a map developed by NOAA. 2. The fourth fact in the reference evidence provides additional information from the image, supporting the description of the map's purpose in the first fact of the predicted evidence. 3. The fifth fact in the reference evidence offers specific details about the image and its context, reinforcing the tenth fact in the predicted evidence, which clarifies the map's function.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_5'], 'score': '10'}, {'info': ['PRED_7', 'REF_5'], 'score': '10'}, {'info': ['PRED_10', 'REF_5'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_2', 'PRED_1'], 'score': '10'}, {'info': ['REF_4', 'PRED_1'], 'score': '10'}, {'info': ['REF_5', 'PRED_10'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 3, 'pred_in_ref': 5, 'detailed_ref_in_pred': '(REF_2,PRED_1);(REF_4,PRED_1);(REF_5,PRED_10)', 'detailed_pred_in_ref': '(PRED_1,REF_5);(PRED_7,REF_5);(PRED_10,REF_5)'}}"
        ],
        [
         "32",
         "0.625",
         "0.75",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 4\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the fifth reference question. 3. The question is covered by the fifth reference question. 4. The question is covered by the fourth reference question. 5. The question is not covered by any reference question. 6. The question is covered by the fifth reference question. 7. The question is covered by the seventh reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 5\\n[REF in PRED Exp]: 1. The question is not covered by the predicted question set. 2. The question is not covered by the predicted question set. 3. The question is not covered by the predicted question set. 4. The question is covered by the fourth predicted question. 5. The question is covered by the fifth and sixth predicted question. 6. The question is not covered by the predicted question set. 7. The question is covered by the seventh predicted question. 8. The question is not covered by the predicted question set.', 'ques_score': {'ref_in_pred': 5, 'pred_in_ref': 4, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Sources describe Gurpatwant Singh Pannun as the founder/leader of Sikhs for Justice and treat him as alive and active; none report his death in any incident. The crash photo used with the claim is from a March 2, 2021 Imperial County, California accident involving smuggled migrants from Mexico and Guatemala, with no connection to Pannun. Since the image is repurposed from an unrelated event and no credible report supports that he died in a U.S. road accident, the claim is refuted.\\n[REF]: The claim is successfully refuted by proving that the image is an accident in 2021 that occurred near the Mexican border and Pannun was not among the victims.\\n[PRED_FACT]: 1. Sources describe Gurpatwant Singh Pannun as the founder/leader of Sikhs for Justice and treat him as alive and active. 2. No sources report Pannun’s death. 3. The crash photo is from a March 2, 2021 Imperial County, California accident involving smuggled migrants from Mexico and Guatemala. 4. The crash photo has no connection to Pannun. 5. The image is repurposed from an unrelated event. 6. No credible report supports Pannun died in a U.S. road accident.\\n[REF_FACT]: 1. The image is an accident in 2021. 2. The accident occurred near the Mexican border. 3. Pannun was not among the victims.\\n[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by the reference fact set. 3. The fact is consistent with the first and second fact in the reference fact set. 4. The fact is not covered by the reference fact set. 5. The fact is not covered by the reference fact set. 6. The fact is similar to the third fact in the reference fact set.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The fact is covered by the third fact in the predicted fact set. 2. The fact is covered by the third and fourth fact in the predicted fact set. 3. The fact is covered by the sixth fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 3, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 5; (PRED_1,REF_5);(PRED_2,REF_8);(PRED_3,REF_5);(PRED_6,REF_5);(PRED_10,REF_5)\\n[PRED in REF Exp]: 1. The first predicted fact aligns with the fifth reference fact, as both state there's no mention of Pannun in the article. 2. The second predicted fact aligns with the eighth reference fact, as both confirm the claim is false. 3. The third predicted fact aligns with the fifth reference fact, as both state there's no mention of Pannun in the article. 4. The sixth predicted fact aligns with the fifth reference fact, as both state there's no mention of Pannun in the article. 5. The tenth predicted fact aligns with the fifth reference fact, as both state there's no mention of Pannun in the article.\\n[REF in PRED]: 6; (REF_1,PRED_5);(REF_2,PRED_5);(REF_3,PRED_5);(REF_4,PRED_5);(REF_6,PRED_6);(REF_7,PRED_7)\\n[REF in PRED Exp]: 1. The first reference fact is supported by the fifth predicted fact. 2. The second reference fact is supported by the fifth predicted fact. 3. The third reference fact is supported by the fifth predicted fact. 4. The fourth reference fact is supported by the fifth predicted fact. 5. The sixth reference fact is supported by the sixth predicted fact. 6. The seventh reference fact is supported by the seventh predicted fact.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_5'], 'score': '10'}, {'info': ['PRED_2', 'REF_8'], 'score': '10'}, {'info': ['PRED_3', 'REF_5'], 'score': '10'}, {'info': ['PRED_6', 'REF_5'], 'score': '10'}, {'info': ['PRED_10', 'REF_5'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_1', 'PRED_5'], 'score': '10'}, {'info': ['REF_2', 'PRED_5'], 'score': '10'}, {'info': ['REF_3', 'PRED_5'], 'score': '10'}, {'info': ['REF_4', 'PRED_5'], 'score': '10'}, {'info': ['REF_6', 'PRED_6'], 'score': '10'}, {'info': ['REF_7', 'PRED_7'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 6, 'pred_in_ref': 5, 'detailed_ref_in_pred': '(REF_1,PRED_5);(REF_2,PRED_5);(REF_3,PRED_5);(REF_4,PRED_5);(REF_6,PRED_6);(REF_7,PRED_7)', 'detailed_pred_in_ref': '(PRED_1,REF_5);(PRED_2,REF_8);(PRED_3,REF_5);(PRED_6,REF_5);(PRED_10,REF_5)'}}"
        ],
        [
         "33",
         "1.0",
         "0.0",
         "0",
         "0.6000000000000001",
         "{'ques_feedback': '[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the fourth reference question. 3. The question is covered by the third reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 4\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is not covered by any predicted question. 3. The question is covered by the first predicted question. 4. The question is covered by the second predicted question.', 'ques_score': {'ref_in_pred': 4, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: News reports confirm that in 2019 a Dalit woman in Rajasthan’s Alwar district was gang-raped in front of her husband and the assailants filmed and later uploaded the video. However, reverse image search shows the circulated photo is associated with unrelated YouTube content and is not linked in the articles covering that crime. The textual part of the claim (that such a crime occurred) is accurate, but there is no evidence that this particular image depicts that incident. Because the claim, as posted with this image, implicitly ties the picture to the Alwar case without supporting evidence, the overall veracity regarding the image-context pairing cannot be firmly classified as supported or refuted.\\n[REF]: The claim that a Dalit woman was gang-raped in front of her husband in Rajasthan, and the accused made a video viral, is supported by the details provided. The incident occurred in Alwar district, Rajasthan, and the family members accused the police of inaction due to the election period, with the crime being reported to the police later.\\n[PRED_FACT]: 1. A Dalit woman in Rajasthan’s Alwar district was gang-raped in front of her husband in 2019. 2. The assailants filmed the gang-rape and uploaded the video. 3. Reverse image search shows the circulated photo is associated with unrelated YouTube content. 4. The photo is not linked in the articles covering the crime. 5. The textual part of the claim is accurate. 6. There is no evidence that this particular image depicts the incident.\\n[REF_FACT]: 1. A Dalit woman was gang-raped in front of her husband in Rajasthan. 2. The accused made a video viral. 3. The incident occurred in Alwar district, Rajasthan. 4. The family members accused the police of inaction. 5. The crime was reported to the police later.\\n[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The fact is not covered by any reference fact. 2. The fact is covered by the first and second fact in the reference fact set. 3. The fact is covered by the third fact in the reference fact set. 4. The fact is not covered by any reference fact. 5. The fact is covered by the first and second fact in the reference fact set. 6. The fact is not covered by any reference fact.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The fact is covered by the first fact in the predicted fact set. 2. The fact is covered by the second fact in the predicted fact set. 3. The fact is covered by the first fact in the predicted fact set. 4. The fact is not covered by any predicted fact. 5. The fact is not covered by any predicted fact.', 'justi_score': {'ref_in_pred': 3, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 4; (PRED_1,REF_4);(PRED_2,REF_4);(PRED_3,REF_2);(PRED_4,REF_3)\\n[PRED in REF Exp]: 1. The predicted evidence confirms the incident happened in Rajasthan's Alwar district. 2. The predicted evidence confirms the incident happened near Thanagazi in Alwar district. 3. The predicted evidence confirms the victim is a Dalit woman. 4. The predicted evidence confirms the video of the gangrape was uploaded online.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence mentions the date of the earliest news report, but the predicted evidence does not specify that date. 2. The reference evidence mentions family members accusing the police, which is not discussed in the predicted evidence. 3. The reference evidence names the accused, not mentioned in the predicted evidence. 4. The predicted evidence refers to the location, which is the same as the fourth reference fact.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_4'], 'score': '10'}, {'info': ['PRED_2', 'REF_4'], 'score': '10'}, {'info': ['PRED_3', 'REF_2'], 'score': '10'}, {'info': ['PRED_4', 'REF_3'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 4, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_1,REF_4);(PRED_2,REF_4);(PRED_3,REF_2);(PRED_4,REF_3)'}}"
        ],
        [
         "34",
         "1.0",
         "0.0",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The predicted questions are all covered by the reference question. The predicted questions are asking for details about an auction that occurred at Osenat Auction House on October 1st 2023, which is exactly what the reference question is asking.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The reference question is covered by the first predicted question.', 'ques_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED]: The poster image appears to advertise an Osenat auction on October 1st, 2023, featuring 'Treasures of the Kiev-Pechersk Lavra,' but none of the provided Osenat documents or other sources independently confirm that such a sale of Orthodox relics from Kyiv actually occurred or was scheduled. The available Osenat material is generic and does not list this event, and other sources about Ukrainian religious objects discuss protective loans and exhibitions rather than auctions. With no corroborating documentation of the specific auction and no way from the sources to verify whether the poster is authentic or fabricated, there is insufficient evidence to determine whether the stated auction of Orthodox relics from Kyiv at Osenat on that date is real or not.\\n[REF]: The claim is successfully refuted by proving that the Interiors of Versailles were auctioned on 10/1/23 at the Osenat Auction House.\\n[PRED_FACT]: 1. The poster image advertises an Osenat auction on October 1st, 2023, featuring 'Treasures of the Kiev-Pechersk Lavra.' 2. None of the provided Osenat documents or other sources confirm the sale of Orthodox relics from Kyiv. 3. The available Osenat material is generic and does not list the event. 4. Other sources discuss protective loans and exhibitions rather than auctions. 5. There is insufficient evidence to determine if the auction is real.\\n[REF_FACT]: 1. The Interiors of Versailles were auctioned on 10/1/23 at the Osenat Auction House.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact. 2. The fact is not covered by the reference fact. 3. The fact is not covered by the reference fact. 4. The fact is not covered by the reference fact. 5. The fact is not covered by the reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact.\", 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence set claims the poster shows the Osenat name and the French text indicating a specific date, which is not mentioned in the reference evidence. 2. The second fact claims details of text on the poster, not mentioned in the reference evidence. 3. The third fact contradicts the reference evidence. 4. The fourth fact contradicts the reference evidence. 5. The fifth fact does not find support in the reference evidence. 6. The sixth fact does not find support in the reference evidence. 7. The seventh fact does not find support in the reference evidence. 8. The eighth fact does not find support in the reference evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence can be found in the predicted evidence to support this fact.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "35",
         "1.0",
         "0.33333333333333304",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. 2. The question is not covered by any reference question. 3. The question is covered by the third reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is covered by the first reference question. 7. The question is not covered by any reference question. 8. The question is covered by the third reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is not covered by any predicted question. 3. The question is covered by the eighth predicted question.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. The photo shows unrest and fires near the Eiffel Tower. 2. The image is from celebrations and disturbances after France’s 2018 World Cup victory. 3. The image is from several years before the claim was made in July 2023. 4. No evidence links the image to riots occurring close to the time of the claim.\\n[REF_FACT]: 1. The image was taken on July 10, 2016, during the EURO 2016 final match. 2. The image depicts clashes near the Eiffel Tower. 3. The image is not from recent riots in 2023.\\n[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The fact is covered by the second fact in the reference fact set. 2. The fact is covered by the third fact in the reference fact set. 3. The fact is covered by the third fact in the reference fact set.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The fact is similar to the first fact in the predicted fact set. 2. The fact is covered by the second fact in the predicted fact set. 3. The fact is covered by the third and fourth facts in the predicted fact set.', 'justi_score': {'ref_in_pred': 3, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_1,REF_2)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence is supported by the second fact in the reference evidence, which describes the scene near the Eiffel Tower during the Euro 2016 final.\\n[REF in PRED]: 1; (REF_3,PRED_7)\\n[REF in PRED Exp]: 1. The third fact in the reference evidence relates to recent riots in France (2023), which is echoed in the seventh fact of the predicted evidence stating that the unrest shown occurred in 2018, not 2023.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_2'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_3', 'PRED_7'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '(REF_3,PRED_7)', 'detailed_pred_in_ref': '(PRED_1,REF_2)'}}"
        ],
        [
         "36",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first reference question. 3. The question is covered by the first reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the first predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Sources agree that Seema Haider is a Pakistani civilian who illegally entered India to live with Sachin Meena and is not a police officer, soldier, or UN peacekeeper. Reverse‑image search shows the uniformed women in the montage are unrelated individuals: Usha Rani Narendra of Tamil Nadu Police, Pakistani female UN peacekeepers, and a fictional character from a Pakistani drama. Only the first image may depict Seema Haider. Therefore, the claim that these photos generally show Seema Haider is false.\\n[REF]: The claim is successfully refuted by proving that the photos are of Major Samia Rehman\\n[PRED_FACT]: 1. Seema Haider is a Pakistani civilian who illegally entered India to live with Sachin Meena. 2. Seema Haider is not a police officer, soldier, or UN peacekeeper. 3. The uniformed women in the montage are unrelated individuals: Usha Rani Narendra of Tamil Nadu Police, Pakistani female UN peacekeepers, and a fictional character from a Pakistani drama. 4. Only the first image may depict Seema Haider. 5. The claim that these photos generally show Seema Haider is false.\\n[REF_FACT]: 1. The photos are of Major Samia Rehman.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the predicted fact set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence provides extensive details about Seema Ghulam Haider and related images, while the reference evidence only identifies the person in the images as Major Samia Rehman. There is no overlap in the information presented.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence's claim about the identity of the person in the image is not supported by any of the detailed explanations and identifications provided in the predicted evidence. The predicted evidence discusses different individuals and scenarios.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "37",
         "1.0",
         "1.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. The predicted question asks for details about what the image shows and where it was taken, which aligns with the reference question asking for the location where the image was taken.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question as it asks for the location of the image.', 'ques_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Reverse image search shows this police van image being used as a still for the 2022 action-thriller film “Athéné/Athena” on Videa. 2. There is no evidence in major news photo coverage that it documents real French protests. 3. The available sources indicate it is a fictional movie scene rather than an authentic protest image from France.\\n[REF_FACT]: 1. The image is a still shot from a video excerpt of the film Athena.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact is consistent with the reference fact.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The fact is covered by the first fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 1; (PRED_1,REF_1)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence aligns with the single fact in the reference evidence, stating the image originates from the film Athena.\\n[REF in PRED]: 1; (REF_1,PRED_9)\\n[REF in PRED Exp]: 1. The reference evidence supports the ninth fact in the predicted evidence, confirming the image's origin as a still from the film “Athéné/Athena” on Videa.\", 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_1', 'PRED_9'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '(REF_1,PRED_9)', 'detailed_pred_in_ref': '(PRED_1,REF_1)'}}"
        ],
        [
         "38",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the first reference question. 3. The question is covered by the second reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the second predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Reverse-image search identifies the depicted building as Villa Nikki Del Mar, a luxury villa in Mallorca, Spain. 2. The building has no connection to Volodymyr Zelenskyy or Ukrainian state residences. 3. Official presidential residences listed for Ukraine are entirely different properties located in Ukraine.\\n[REF_FACT]: 1. The image is a house in France. 2. Zelenskyy lives in the Mariinskyi Palace.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The predicted fact about the location being in Mallorca, Spain is not covered by the reference fact stating the location is in France. 2. The predicted fact about the building having no connection to Zelenskyy is not directly covered by the reference, though it implies it. 3. The predicted fact about Ukrainian presidential residences is not mentioned in the reference.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The reference fact about the image being in France is not covered by any predicted fact. 2. The reference fact about Zelenskyy living in the Mariinskyi Palace is not covered by any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence does not mention the Mariinskyi Palace. 2. The predicted evidence does not mention that the house in the image is in France.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence. 2. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "39",
         "1.0",
         "0.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the reference question.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The reference question is covered by the first predicted question.', 'ques_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. The visual is based on standard composite or computer-generated day–night Earth imagery. 2. The image is not a single, rare photograph capturing day and night simultaneously over Africa and Europe. 3. NASA explains that such images are assembled from multiple datasets, with clouds removed and city lights overlaid. 4. The relative brightness of lights and the visible ocean-floor features show it is not a real-time photo. 5. The claim that this is a rare photo is misleading.\\n[REF_FACT]: 1. The image is a digital composite. 2. The image is not a real photo.\\n[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The first fact is covered by the first and second fact in the reference fact set. 2. The second fact is covered by the second fact in the reference fact set. 3. The third fact provides additional details about the first reference fact. 4. The fourth fact provides additional details supporting the reference facts. 5. The fifth fact is a conclusion based on the previous facts and is consistent with the reference.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The first fact in the reference is covered by the first and second fact in the predicted fact set. 2. The second fact in the reference is covered by the second fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence provides extensive details regarding the image, its creation, and NASA\\'s explanations, while the reference evidence simply identifies the image as a \"Digital Sunset Over Europe and Africa.\" There\\'s no direct overlap in information.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence offers a basic description of the image, which is not directly supported or contradicted by any specific claim within the detailed predicted evidence. The predicted evidence focuses on the image\\'s composition and scientific context, going far beyond the scope of the reference evidence\\'s identification.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "40",
         "1.0",
         "0.5",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The first predicted question is covered by the first reference question. 2. The questions are not covered by nor similar to any reference question. 3. The questions are not covered by nor similar to any reference question. 4. The questions are not covered by nor similar to any reference question. 5. The questions are not covered by nor similar to any reference question. 6. The questions are not covered by nor similar to any reference question. 7. The questions are not covered by nor similar to any reference question. 8. The questions are not covered by nor similar to any reference question. 9. The questions are not covered by nor similar to any reference question. 10. The questions are not covered by nor similar to any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is not covered by the predicted question set. 2. The question is covered by the sixth predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED]: Authorities report that Tafari Campbell, the Obamas’ personal chef, accidentally drowned while paddleboarding, and Massachusetts State Police and the medical examiner found no evidence his death was suspicious. Reports explicitly state that online stories claiming Obama’s hand bandages are suspicious and imply his involvement in the chef’s death are incorrect. The widely shared golf photo showing Obama with bandaged fingers is a file image from 2014 in Hawaii, not from the time of Campbell’s 2023 death. None of the sources provide any evidence linking Obama or his bandaged hand to causing Campbell’s death, so the claim that the bandages are suspicious and suggest his involvement is refuted.\\n[REF]: The claim is successfully refuted by proving that the Obamas were not visiting Martha's Vineyard where and when the death occurred. Further, it is demonstrated with a personal account how golfers frequently tape their fingers to prevent blisters. CLAIM_IMG_2 clearly shows Obama with a golf iron in his right hand.\\n[PRED_FACT]: 1. Tafari Campbell, the Obamas’ personal chef, accidentally drowned while paddleboarding. 2. Massachusetts State Police and the medical examiner found no evidence his death was suspicious. 3. Online stories claiming Obama’s hand bandages are suspicious and imply his involvement in the chef’s death are incorrect. 4. The golf photo showing Obama with bandaged fingers is a file image from 2014 in Hawaii. 5. There is no evidence linking Obama or his bandaged hand to causing Campbell’s death.\\n[REF_FACT]: 1. The Obamas were not visiting Martha's Vineyard where and when the death occurred. 2. Golfers frequently tape their fingers to prevent blisters. 3. CLAIM_IMG_2 shows Obama with a golf iron in his right hand.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that Obama was not visiting Martha's Vineyard is not covered by the predicted fact set. 2. The fact is not covered by nor similar to any predicted fact. 3. The fact is not covered by nor similar to any predicted fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact. 2. The fact is not covered by nor similar to any predicted fact. 3. The fact is not covered by nor similar to any predicted fact.\", 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence provides details regarding a chef's death and conspiracy theories surrounding it, while the reference evidence only states the chef's death. 2. The predicted evidence discusses bandages and conspiracy theories, which are not mentioned in the reference evidence.\\n[REF in PRED]: 1; (REF_1,PRED_2)\\n[REF in PRED Exp]: 1. The first fact in the reference evidence is supported by the second fact in the predicted evidence, which details the chef's death. 2. The predicted evidence doesn't mention golfers or blisters on hands from playing golf.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': [{'info': ['REF_1', 'PRED_2'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 1, 'pred_in_ref': 0, 'detailed_ref_in_pred': '(REF_1,PRED_2)', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "41",
         "0.0",
         "0.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 0\\n[PRED in REF Exp]: None of the predicted questions are covered by the reference questions. The predicted questions focus on verifying a specific claim about a Texas convenience store robbery using multiple sources (text and images), while the reference questions ask about the origin of an image and a specific robbery in Brazil.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The question is not covered by the predicted question set. 2. The question is not covered by the predicted question set.', 'ques_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. News reports describe somewhat similar incidents, such as a single armed customer shooting a robber in a Houston taqueria. 2. None of the sources report a case where every customer in a Texas convenience store shot a robber dead. 3. The CCTV-style image in the meme is reused from unrelated contexts. 4. The image is not tied to a verified Texas event. 5. With no corroborating evidence and multiple indications that the meme misrepresents reality, the claim is best classified as refuted.\\n[REF_FACT]: 1. The image was taken in Brazil. 2. The image was not taken in Texas. 3. Therefore, the claim is refuted.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact that the image is not from Texas (fact 2 in REF) is covered by the predicted fact that the image is reused from unrelated contexts (fact 3 in PRED) and not tied to a verified Texas event (fact 4 in PRED). The other facts are not covered.\\n[REF in PRED]: 1\\n[REF in PRED Exp]: 1. The fact that the image was taken in Brazil (fact 1 in REF) is covered by the predicted fact that the image is reused from unrelated contexts (fact 3 in PRED) and not tied to a verified Texas event (fact 4 in PRED). The other facts are not covered.', 'justi_score': {'ref_in_pred': 1, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence focuses on events in Texas, while the reference evidence describes an incident in Brazil. 2. The reference evidence provides details about a robbery in Brazil involving off-duty police officers, which is not mentioned in the predicted evidence. The remaining predicted facts relate to debunking a specific claim and do not align with the reference evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence describes an event in Brazil, which is not discussed in the predicted evidence focusing on Texas events and debunking a specific claim. The predicted evidence analyzes similar but ultimately unrelated incidents and does not corroborate the details provided in the reference evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "42",
         "1.0",
         "0.0",
         "1",
         "1.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by the reference question set. 2. The question is covered by the second reference question. 3. The question is not covered by the reference question set. 4. The question is not covered by the reference question set. 5. The question is covered by the second reference question. 6. The question is not covered by the reference question set. 7. The question is not covered by the reference question set. 8. The question is not covered by the reference question set. 9. The question is not covered by the reference question set. 10. The question is similar to the first reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The first reference question is covered by the tenth predicted question. 2. The second reference question is covered by the second and fifth predicted questions.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Biden did visit Finland in July 2023. 2. None of the sources connect the specific photo to that visit or to Finland. 3. Reverse-image-related sources indicate the visually similar images are from European protests over COVID-19 restrictions or other issues in earlier years. 4. The photo is not from Finnish protests against Biden’s 2023 visit.\\n[REF_FACT]: 1. The image depicts a protest in Stockholm on March 6, 2021. 2. The image is not a protest against Biden in Finland in 2023.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact is covered by the second fact in the reference set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set. 4. The fact is covered by the second fact in the reference set.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The fact is covered by the third and fourth fact in the predicted fact set. 2. The fact is covered by the fourth fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence discusses Joe Biden's visit to Helsinki, Finland, while the reference evidence concerns a protest in Stockholm, Sweden. 2. The predicted evidence details aspects of Biden's visit and potential protests, but the reference evidence focuses on an anti-lockdown protest in a different city and time. 3. The predicted evidence questions the connection of a specific image to Biden's visit, and the reference evidence identifies the image as a protest in Stockholm. 4. The predicted evidence provides multiple 'yes' or 'no' answers related to protests and Biden’s visit, which have no correlation to the reference evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence describes a protest in Stockholm, Sweden, while the predicted evidence relates to a visit by Joe Biden to Helsinki, Finland, therefore there is no overlapping information. 2. The timing of the reference image (March 2021) does not align with any events discussed within the predicted evidence (July 2023).\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "43",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 3\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. 2. The question is covered by the second reference question. 3. The question is covered by the third reference question. 4. The question is not covered by any reference question. 5. The question is covered by the first reference question. 6. The question is covered by the first reference question. 7. The question is covered by the second reference question. 8. The question is covered by the third reference question. 9. The question is not covered by any reference question. 10. The question is covered by the first, second and third reference questions.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the second predicted question. 3. The question is covered by the third predicted question.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 3, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: The claim asserts that three major Pakistani newspapers—Dawn, The Express Tribune, and The News—did not publish on their front pages news about the hundreds of Pakistanis who drowned in the Greece boat disaster in June 2023. However, Source 1 from Dawn explicitly describes a front‑page story about the Greece shipwreck and Pakistani victims, reporting on missing and dead Pakistanis and the creation of an FIA team to pursue human traffickers. The image shows this Dawn story on the front page. While the available sources do not detail the exact June 18, 2023 front pages of The Express Tribune or The News, the fact that at least one of the three named papers (Dawn) did feature such coverage on its front page is sufficient to render the blanket statement that all three “did not publish” such news false.\\n[REF]: The claim is refuted by QA pairs. However, neither of the three links are working.\\n[PRED_FACT]: 1. The claim asserts that three Pakistani newspapers—Dawn, The Express Tribune, and The News—did not publish news about the Greece boat disaster on their front pages. 2. Source 1 from Dawn describes a front-page story about the Greece shipwreck and Pakistani victims. 3. The image shows a Dawn story on the front page. 4. The available sources do not detail the front pages of The Express Tribune or The News. 5. The fact that Dawn featured coverage on its front page renders the claim false.\\n[REF_FACT]: 1. The claim is refuted by QA pairs. 2. None of the three links are working.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The predicted fact is not covered by nor similar to any reference fact. 2. The predicted fact is not covered by nor similar to any reference fact. 3. The predicted fact is not covered by nor similar to any reference fact. 4. The predicted fact is not covered by nor similar to any reference fact. 5. The predicted fact is not covered by nor similar to any reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact. 2. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 3; (PRED_1,REF_1);(PRED_2,REF_2);(PRED_10,REF_3)\\n[PRED in REF Exp]: 1. The first fact in the predicted evidence claims the image displays the front pages of the three newspapers, which is supported by the first fact in the reference evidence. 2. The second fact in the predicted evidence, regarding Dawn’s headline, is supported by the second fact in the reference evidence. 3. The tenth fact in the predicted evidence claims Dawn carried news on the incident, which is similar to the third fact in the reference evidence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence set. 2. No relevant evidence could be found in the predicted evidence set. 3. No relevant evidence could be found in the predicted evidence set.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_2', 'REF_2'], 'score': '10'}, {'info': ['PRED_10', 'REF_3'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 3, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_2,REF_2);(PRED_10,REF_3)'}}"
        ],
        [
         "44",
         "1.0",
         "1.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second reference question. 3. The question is covered by the first reference question. 4. The question is not covered by any reference question. 5. The question is covered by the second reference question. 6. The question is not covered by any reference question. 7. The question is covered by the first reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is covered by the first and second reference questions.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the first predicted question. 2. The question is covered by the fourth, fifth and sixth predicted questions.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Narendra Modi is the first Indian prime minister to address a joint meeting of the U.S. Congress twice. 2. Other world leaders besides Winston Churchill have addressed a joint meeting of the U.S. Congress twice, including Nelson Mandela. 3. Churchill himself addressed Congress three times. 4. The claim that Modi is the only world leader apart from Churchill to have addressed the U.S. Congress twice is factually incorrect.\\n[REF_FACT]: 1. The claim is successfully refuted by providing official U.S. proof that others aside from Modi have addressed the capitol joint meeting of Congress more than twice.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: The predicted fact that others have addressed Congress more than twice is covered by the reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: The reference fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 9; (PRED_1,REF_1);(PRED_2,REF_1);(PRED_3,REF_1);(PRED_4,REF_2);(PRED_5,REF_2);(PRED_8,REF_2);(PRED_10,REF_2);(PRED_7,REF_2);(PRED_9,REF_2)\\n[PRED in REF Exp]: 1. The predicted fact is supported by the first reference fact. 2. The predicted fact is supported by the first reference fact. 3. The predicted fact is supported by the first reference fact. 4. The predicted fact is supported by the second reference fact. 5. The predicted fact is supported by the second reference fact. 6. The predicted fact is supported by the second reference fact. 7. The predicted fact is supported by the second reference fact. 8. The predicted fact is supported by the second reference fact. 9. The predicted fact is supported by the second reference fact.\\n[REF in PRED]: 2; (REF_1,PRED_1);(REF_2,PRED_4)\\n[REF in PRED Exp]: 1. The first reference fact is supported by the first predicted fact. 2. The second reference fact is supported by the fourth predicted fact.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_1', 'REF_1'], 'score': '10'}, {'info': ['PRED_2', 'REF_1'], 'score': '10'}, {'info': ['PRED_3', 'REF_1'], 'score': '10'}, {'info': ['PRED_4', 'REF_2'], 'score': '10'}, {'info': ['PRED_5', 'REF_2'], 'score': '10'}, {'info': ['PRED_8', 'REF_2'], 'score': '10'}, {'info': ['PRED_10', 'REF_2'], 'score': '10'}, {'info': ['PRED_7', 'REF_2'], 'score': '10'}, {'info': ['PRED_9', 'REF_2'], 'score': '10'}], 'ref_in_pred': [{'info': ['REF_1', 'PRED_1'], 'score': '10'}, {'info': ['REF_2', 'PRED_4'], 'score': '10'}]}, 'evid_text_score': {'ref_in_pred': 2, 'pred_in_ref': 9, 'detailed_ref_in_pred': '(REF_1,PRED_1);(REF_2,PRED_4)', 'detailed_pred_in_ref': '(PRED_1,REF_1);(PRED_2,REF_1);(PRED_3,REF_1);(PRED_4,REF_2);(PRED_5,REF_2);(PRED_8,REF_2);(PRED_10,REF_2);(PRED_7,REF_2);(PRED_9,REF_2)'}}"
        ],
        [
         "45",
         "1.0",
         "0.0",
         "0",
         "0.6666666666666661",
         "{'ques_feedback': '[PRED in REF]: 2\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is covered by the second reference question. 3. The question is not covered by any reference question. 4. The question is covered by the second reference question. 5. The question is not covered by any reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is covered by the second reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is covered by the seventh predicted question. 2. The question is covered by the first, second and tenth predicted questions.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 2, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': \"[PRED_FACT]: 1. Available reports on the Panchagarh violence confirm at least two deaths. 2. One victim is Zahid Hasan, an Ahmadi engineer killed during the attack on the Ahmadiyya Jalsa. 3. None of the provided sources mention a person named Mohammad Rifat Anjum in connection with these events. 4. None of the provided sources document Mohammad Rifat Anjum's death as part of an anti‑Qadiani movement. 5. The specific claim about Mohammad Rifat Anjum cannot be conclusively refuted or supported based on the evidence at hand.\\n[REF_FACT]: 1. The source names two people who died whose names are not Anjum. 2. Nothing in the source refers to anti-Qadiani persons. 3. The article provided mentions the Ahmadiyya community only.\\n[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The fact is covered by the first and second facts in the reference fact set. 2. The fact is covered by the first and third facts in the reference fact set. 3. The fact is covered by the second fact in the reference fact set. 4. The fact is covered by the second fact in the reference fact set. 5. This fact is not covered by nor similar to any reference fact.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The fact is similar to the first fact in the predicted fact set. 2. The fact is similar to the third and fourth facts in the predicted fact set. 3. The fact is covered by the third and fourth facts in the predicted fact set.\", 'justi_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 1; (PRED_2,REF_2)\\n[PRED in REF Exp]: 1. The second fact in the predicted evidence aligns with the second fact in the reference evidence, both confirming the deaths of Zahid Hasan and Ariful Haque during the Panchagarh clashes.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The first fact in the reference evidence is not supported by any fact in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [{'info': ['PRED_2', 'REF_2'], 'score': '10'}], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 1, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': '(PRED_2,REF_2)'}}"
        ],
        [
         "46",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is covered by the first reference question. 2. The question is not covered by the reference questions. 3. The question is not covered by the reference questions. 4. The question is covered by the third reference question. 5. The question is not covered by the reference questions. 6. The question is not covered by the reference questions. 7. The question is covered by the second reference question. 8. The question is not covered by the reference questions. 9. The question is not covered by the reference questions. 10. The question is not covered by the reference questions.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is covered by the seventh predicted question. 3. The question is covered by the fourth predicted question.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Available sources show that the image is a stock/photo used in a Metro article about stolen dachshunds, not about a missing child. The only well‑documented missing girl named Sofia (Sofia Juarez) disappeared on foot and triggered an AMBER Alert, not a Silver Alert. Silver Alerts are designed for missing elderly people with dementia, not five‑year‑old children. No evidence supports the specific scenario of a five‑year‑old Sofia missing after a bike ride with a Silver Alert issued, so the claim is refuted.\\n[REF]: The claim is successfully refuted by proving that the child is named Ruby, she lives in the UK, and that silver alerts are issued in the U.S. for missing senior citizens.\\n[PRED_FACT]: 1. The image is a stock/photo used in a Metro article about stolen dachshunds, not about a missing child. 2. The only well-documented missing girl named Sofia (Sofia Juarez) disappeared on foot and triggered an AMBER Alert, not a Silver Alert. 3. Silver Alerts are designed for missing elderly people with dementia, not five‑year‑old children.\\n[REF_FACT]: 1. The child is named Ruby. 2. The child lives in the UK. 3. Silver alerts are issued in the U.S. for missing senior citizens.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by nor similar to any reference fact. 3. The fact is not covered by nor similar to any reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by the predicted fact set. 2. The fact is not covered by the predicted fact set. 3. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence does not mention the girl’s name being Ruby. 2. The predicted evidence does not mention the Silver Alert program operating in the US. 3. The predicted evidence does not mention the claim being made in the United Kingdom.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence. 2. No relevant evidence could be found in the predicted evidence. 3. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "47",
         "0.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 0\\n[PRED in REF Exp]: None of the predicted questions are covered by the reference questions. The predicted questions focus on verifying the location, date, and authenticity of images related to Mayon Volcano, while the reference questions are about the original publisher and caption of the images.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: The reference questions are not covered by the predicted question set. The predicted questions do not ask about the original publisher or caption of the images.', 'ques_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED]: Reverse image search shows that key images in the collage are long-standing photos of other volcanoes: Source 22 identifies a matching image as Arenal Volcano in Costa Rica, and sources 41–44 identify another as Fuego Volcano in Guatemala, all published well before 2023. None of the matched sources or Mayon-specific 2023 coverage (Source 4) use these images or locate them in the Philippines. Thus the images are not genuine depictions of Mayon’s 2023 eruption.\\n[REF]: The claim is successfully refuted by proving that the images are AI-generated by Herol de Guzman.\\n[PRED_FACT]: 1. Key images in the collage are long-standing photos of other volcanoes. 2. Source 22 identifies a matching image as Arenal Volcano in Costa Rica. 3. Sources 41–44 identify another image as Fuego Volcano in Guatemala. 4. These volcanoes’ images were published well before 2023. 5. None of the matched sources or Mayon-specific 2023 coverage use these images or locate them in the Philippines. 6. The images are not genuine depictions of Mayon’s 2023 eruption.\\n[REF_FACT]: 1. The images are AI-generated by Herol de Guzman.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact. 2. The fact is not covered by the reference fact. 3. The fact is not covered by the reference fact. 4. The fact is not covered by the reference fact. 5. The fact is not covered by the reference fact. 6. The fact is not covered by the reference fact.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence does not mention the original publisher of the images. 2. The predicted evidence does not mention the original caption of the images.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. No relevant evidence could be found in the predicted evidence. 2. No relevant evidence could be found in the predicted evidence.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "48",
         "1.0",
         "0.0",
         "1",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is not covered by any reference question. 3. The question is covered by the third reference question. 4. The question is not covered by any reference question. 5. The question is covered by the first reference question. 6. The question is not covered by any reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question. 9. The question is not covered by any reference question. 10. The question is not covered by any reference question.\\n[REF in PRED]: 3\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is not covered by any predicted question. 3. The question is covered by the third predicted question.', 'ques_score': {'ref_in_pred': 3, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. None of the sources describe or announce a Google Maps feature that lets drivers challenge each other to a race. 2. Documented updates focus on navigation, safety incident reporting, and cosmetic themes like a Mario Kart avatar. 3. The race-challenge interface in the image appears to be a conceptual or humorous mockup, not an official Google Maps feature.\\n[REF_FACT]: 1. The image is from a satirical source.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any fact in the predicted fact set.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': '[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence focuses on Google Maps features and denies racing functionalities, while the reference evidence describes the origin and nature of an image ([IMG_1]) as a satirical UI design by Soren Iverson. There is no overlap in content. 2. The predicted evidence does not mention Soren Iverson or his work at Cash App. 3. The predicted evidence does not mention the satirical nature of the image or its publication on Twitter.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence details the creator and context of an image, information absent in the predicted evidence. 2. The predicted evidence does not contain any information about Soren Iverson or his design work. 3. The predicted evidence centers on functionality and denials related to Google Maps, while the reference evidence is about the origin of a specific image.', 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ],
        [
         "49",
         "1.0",
         "0.0",
         "0",
         "0.0",
         "{'ques_feedback': '[PRED in REF]: 1\\n[PRED in REF Exp]: 1. The question is not covered by any reference question. 2. The question is not covered by any reference question. 3. The question is not covered by any reference question. 4. The question is not covered by any reference question. 5. The question is not covered by any reference question. 6. The question is covered by the first reference question. 7. The question is not covered by any reference question. 8. The question is not covered by any reference question.\\n[REF in PRED]: 2\\n[REF in PRED Exp]: 1. The question is not covered by any predicted question. 2. The question is not covered by any predicted question.', 'ques_score': {'ref_in_pred': 2, 'pred_in_ref': 1, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'justi_feedback': '[PRED_FACT]: 1. Available sources confirm widespread ethnic violence in Manipur. 2. Available sources document cases of misattributed images. 3. None of the sources verifies or debunks this particular photo. 4. None of the sources provides the origin, date, or location of the photo. 5. The claim that this image shows a victim of the Meitei–Kuki violence cannot be confidently classified as true or false.\\n[REF_FACT]: 1. The image is of 2021 domestic violence. 2. The image is not of 2023 ethnic violence.\\n[PRED in REF]: 0\\n[PRED in REF Exp]: 1. The fact is not covered by the reference fact set. 2. The fact is not covered by the reference fact set. 3. The fact is not covered by the reference fact set. 4. The fact is not covered by the reference fact set. 5. The fact is not covered by the reference fact set.\\n[REF in PRED]: 0\\n[REF in PRED Exp]: 1. The fact is not covered by nor similar to any predicted fact. 2. The fact is not covered by nor similar to any predicted fact.', 'justi_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': '', 'detailed_pred_in_ref': ''}, 'evid_feedback': \"[PRED in REF]: 0; None\\n[PRED in REF Exp]: 1. The predicted evidence focuses on the verification of an image's context related to the 2023 Manipur violence and doesn't contain information about the image's original sharing date or the communities involved in the violence. 2. The predicted evidence focuses on the verification of an image's context related to the 2023 Manipur violence and doesn't contain information about the communities involved in the violence.\\n[REF in PRED]: 0; None\\n[REF in PRED Exp]: 1. The reference evidence provides the date the image was originally shared and the communities involved in the violence, information not addressed in the predicted evidence. 2. The reference evidence indicates the violence occurred in May 2023, not discussed within the predictions.\", 'evid_image_score': {'pred_in_ref': [], 'ref_in_pred': []}, 'evid_text_score': {'ref_in_pred': 0, 'pred_in_ref': 0, 'detailed_ref_in_pred': 'None', 'detailed_pred_in_ref': 'None'}}"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 60
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_score</th>\n",
       "      <th>evid_score</th>\n",
       "      <th>verdict_score</th>\n",
       "      <th>justi_score</th>\n",
       "      <th>intermediate_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 4\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 4\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 4\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 10\n",
       "[PRED in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ques_score  evid_score  verdict_score  justi_score  \\\n",
       "0     1.000000    1.000000              1     1.000000   \n",
       "1     1.000000    0.250000              1     0.666667   \n",
       "2     0.000000    0.000000              1     0.000000   \n",
       "3     0.333333    0.000000              1     0.000000   \n",
       "4     1.000000    0.000000              0     0.000000   \n",
       "5     0.500000    0.333333              1     1.000000   \n",
       "6     1.000000    0.333333              0     0.500000   \n",
       "7     0.000000    0.000000              0     0.000000   \n",
       "8     0.000000    0.000000              0     0.000000   \n",
       "9     1.000000    0.000000              1     0.000000   \n",
       "10    1.000000    0.250000              0     0.000000   \n",
       "11    0.200000    0.200000              1     1.000000   \n",
       "12    1.000000    0.750000              1     0.666667   \n",
       "13    1.000000    0.000000              0     0.000000   \n",
       "14    1.000000    0.000000              1     1.000000   \n",
       "15    1.000000    0.000000              1     1.000000   \n",
       "16    1.000000    0.000000              1     0.000000   \n",
       "17    1.000000    0.000000              1     0.000000   \n",
       "18    0.500000    0.250000              0     0.000000   \n",
       "19    0.666667    0.000000              0     0.500000   \n",
       "20    1.000000    0.000000              1     1.000000   \n",
       "21    1.000000    0.000000              1     1.000000   \n",
       "22    1.000000    0.500000              1     1.000000   \n",
       "23    1.000000    0.500000              1     1.000000   \n",
       "24    0.833333    0.333333              1     1.000000   \n",
       "25    1.000000    0.000000              1     0.333333   \n",
       "26    0.000000    0.000000              1     0.000000   \n",
       "27    1.000000    0.333333              0     0.000000   \n",
       "28    1.000000    0.200000              1     1.000000   \n",
       "29    1.000000    0.000000              1     0.000000   \n",
       "30    0.200000    0.200000              0     0.000000   \n",
       "31    1.000000    0.600000              1     1.000000   \n",
       "32    0.625000    0.750000              1     1.000000   \n",
       "33    1.000000    0.000000              0     0.600000   \n",
       "34    1.000000    0.000000              0     0.000000   \n",
       "35    1.000000    0.333333              1     1.000000   \n",
       "36    1.000000    0.000000              1     0.000000   \n",
       "37    1.000000    1.000000              1     1.000000   \n",
       "38    1.000000    0.000000              1     0.000000   \n",
       "39    1.000000    0.000000              1     1.000000   \n",
       "40    1.000000    0.500000              1     0.000000   \n",
       "41    0.000000    0.000000              1     1.000000   \n",
       "42    1.000000    0.000000              1     1.000000   \n",
       "43    1.000000    0.000000              1     0.000000   \n",
       "44    1.000000    1.000000              1     0.000000   \n",
       "45    1.000000    0.000000              0     0.666667   \n",
       "46    1.000000    0.000000              1     0.000000   \n",
       "47    0.000000    0.000000              1     0.000000   \n",
       "48    1.000000    0.000000              1     0.000000   \n",
       "49    1.000000    0.000000              0     0.000000   \n",
       "50    1.000000    0.000000              1     1.000000   \n",
       "51    1.000000    1.000000              1     0.000000   \n",
       "52    1.000000    0.000000              0     0.000000   \n",
       "53    1.000000    1.000000              1     1.000000   \n",
       "54    1.000000    0.000000              1     0.333333   \n",
       "55    1.000000    0.000000              1     0.500000   \n",
       "56    1.000000    0.666667              1     1.000000   \n",
       "57    1.000000    0.750000              1     1.000000   \n",
       "58    1.000000    0.333333              1     1.000000   \n",
       "59    1.000000    0.000000              1     1.000000   \n",
       "\n",
       "                                    intermediate_info  \n",
       "0   {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "1   {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "2   {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "3   {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "4   {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "5   {'ques_feedback': '[PRED in REF]: 4\n",
       "[PRED in R...  \n",
       "6   {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "7   {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "8   {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "9   {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "10  {'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...  \n",
       "11  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "12  {'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...  \n",
       "13  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "14  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "15  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "16  {'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...  \n",
       "17  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "18  {'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...  \n",
       "19  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "20  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "21  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "22  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "23  {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "24  {'ques_feedback': '[PRED in REF]: 4\n",
       "[PRED in R...  \n",
       "25  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "26  {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "27  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "28  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "29  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "30  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "31  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "32  {'ques_feedback': '[PRED in REF]: 4\n",
       "[PRED in R...  \n",
       "33  {'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...  \n",
       "34  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "35  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "36  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "37  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "38  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "39  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "40  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "41  {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "42  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "43  {'ques_feedback': '[PRED in REF]: 3\n",
       "[PRED in R...  \n",
       "44  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "45  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "46  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "47  {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "48  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "49  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "50  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "51  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "52  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "53  {'ques_feedback': '[PRED in REF]: 10\n",
       "[PRED in ...  \n",
       "54  {'ques_feedback': '[PRED in REF]: 0\n",
       "[PRED in R...  \n",
       "55  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  \n",
       "56  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "57  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "58  {'ques_feedback': '[PRED in REF]: 2\n",
       "[PRED in R...  \n",
       "59  {'ques_feedback': '[PRED in REF]: 1\n",
       "[PRED in R...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load /mnt/data/factcheck/averimatec/prepare_submission/intermediate_eval_results/gemma_gemma_4.json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "df = pd.read_json(\"/mnt/data/factcheck/averimatec/prepare_submission/intermediate_eval_results/gemma_gemma_4.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94291f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2227777777777777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean evid score\n",
    "df[\"evid_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7628337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2833333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of evid score > 0.3 and verdict correct\n",
    "len(df[(df[\"evid_score\"] > 0.3) & (df[\"verdict_score\"] == 1.0)]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318a764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
