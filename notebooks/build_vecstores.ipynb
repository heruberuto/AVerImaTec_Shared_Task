{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9322c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random,os\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "DATA_DIR = \"/mnt/data/factcheck/averimatec\"\n",
    "SPLIT = \"test\"\n",
    "EMBEDDING_MODEL, EMBEDDING_NAME = \"mixedbread-ai/mxbai-embed-large-v1\", \"mxbai\"\n",
    "CROP_SIZE, CROP_SIZE_STR = 2000, \"2k\"\n",
    "TOKENS_PER_CHAR = 0.25\n",
    "EMBEDDING_INPUT_SIZE = 512 # Mxbai-Embedding max input size\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL, model_kwargs={\"device\": \"cuda:0\"})\n",
    "random.seed(111)\n",
    "\n",
    "with open(f\"{DATA_DIR}/{SPLIT}.json\") as f:\n",
    "    datapoints = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bcdaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2023-10-12',\n",
       " 'location': 'IL',\n",
       " 'claim_text': \"Photo shows a deceased newborn being recovered from rubble in the aftermath of Israel's recent airstrikes on the city of Gaza.\",\n",
       " 'claim_images': ['6787bb68e2f02e5f498179d1#CLAIM#0.jpg'],\n",
       " 'metadata': {'speaker': '@sWilinsonbc',\n",
       "  'transcription': '',\n",
       "  'media_source': '',\n",
       "  'original_claim_url': '',\n",
       "  'reporting_source': 'X (formally Twitter)',\n",
       "  'modality': 'Image-text',\n",
       "  'image_used': 'Yes'},\n",
       " 'questions': [],\n",
       " 'justification': '',\n",
       " 'article': '',\n",
       " 'label': ''}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b6ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5096c4e4464b46aa105db2a3761d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for CLAIM_ID in tqdm(range(0,len(datapoints))):# Naive version with \\n concatenated url2texts:   \n",
    "    # skip if f\"{DATA_DIR}/data_store/vecstore/{SPLIT}/4k/{CLAIM_ID}\" exists\n",
    "    if os.path.exists(f\"{DATA_DIR}/vector_store/{SPLIT}/text/{CROP_SIZE_STR}_{EMBEDDING_NAME}/{CLAIM_ID}\"):\n",
    "        continue\n",
    "\n",
    "    os.makedirs(f\"{DATA_DIR}/vector_store/{SPLIT}/text/{CROP_SIZE_STR}_{EMBEDDING_NAME}/{CLAIM_ID}\")\n",
    "\n",
    "    datapoint = datapoints[CLAIM_ID]\n",
    "    claim = datapoint[\"claim_text\"]\n",
    "    # display(Markdown(\"### ðŸ—¯ï¸ \" + claim + \" [\" + datapoint[\"label\"] + \"]\"))\n",
    "    docstore = []\n",
    "    # /mnt/data/factcheck/averimatec/knowledge_store/val/text_related/text_related_store_text_val\n",
    "    for line in open(f\"{DATA_DIR}/knowledge_store/{SPLIT}/text_related/text_related_store_text_{SPLIT}/{CLAIM_ID}.json\"):\n",
    "        docstore.append(json.loads(line))\n",
    "\n",
    "    documents = [\n",
    "        Document(\n",
    "            page_content=\" \".join(doc[\"url2text\"]),\n",
    "            metadata={\n",
    "                \"url\": doc[\"url\"],\n",
    "                # \"sentences\": doc[\"url2text\"]\n",
    "            },\n",
    "        )\n",
    "        for doc in docstore\n",
    "    ]\n",
    "\n",
    "    chunks = []\n",
    "    for doc in docstore:\n",
    "        if not doc[\"url2text\"]:\n",
    "            continue\n",
    "        buffer = \"\"\n",
    "        for i, sentence in enumerate(doc[\"url2text\"]):\n",
    "            if (\n",
    "                i == len(doc[\"url2text\"]) - 1\n",
    "                or len(buffer) + len(sentence) >= EMBEDDING_INPUT_SIZE / TOKENS_PER_CHAR\n",
    "            ):\n",
    "                context_before = \"\"\n",
    "                if chunks and chunks[-1].metadata[\"url\"] == doc[\"url\"]:\n",
    "                    chunks[-1].metadata[\"context_after\"] = buffer\n",
    "                    context_before = chunks[-1].page_content\n",
    "                chunks.append(\n",
    "                    Document(\n",
    "                        page_content=buffer,\n",
    "                        metadata={\"url\": doc[\"url\"], \"context_before\": context_before, \"context_after\": \"\"},\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                buffer = \"\"\n",
    "            buffer += sentence + \" \"\n",
    "    # chunk the documents into smaller pieces\n",
    "    chid = random.randint(0, len(chunks))\n",
    "\n",
    "    # display(Markdown(chunks[chid].metadata[\"context_before\"]))\n",
    "    # display(Markdown(chunks[chid].page_content))\n",
    "    # display(Markdown(chunks[chid].metadata[\"context_after\"]))\n",
    "\n",
    "    # print(chunks[chid].page_content)\n",
    "    retriever = BM25Retriever.from_documents(\n",
    "        chunks, k=CROP_SIZE\n",
    "    )\n",
    "    chunks_pruned = retriever.invoke(claim)\n",
    "    db = FAISS.from_documents(chunks_pruned, embeddings)\n",
    "    db.save_local(f\"{DATA_DIR}/vector_store/{SPLIT}/text/{CROP_SIZE_STR}_{EMBEDDING_NAME}/{CLAIM_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df36672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrade sentence_transformers and transformers to the latest version\n",
    "%pip install -U sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which device embeddings use\n",
    "import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.current_device(), torch.cuda.get_device_name(0))\n",
    "print(torch.__version__)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"google/embeddinggemma-300m\")\n",
    "#make sure the embeddings are on cuda\n",
    "print(embeddings.client.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8d8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
