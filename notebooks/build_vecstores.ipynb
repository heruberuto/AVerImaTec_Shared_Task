{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9322c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random,os\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "DATA_DIR = \"/mnt/data/factcheck/averimatec\"\n",
    "SPLIT = \"val\"\n",
    "EMBEDDING_MODEL, EMBEDDING_NAME = \"mixedbread-ai/mxbai-embed-large-v1\", \"mxbai\"\n",
    "CROP_SIZE, CROP_SIZE_STR = 2000, \"2k\"\n",
    "TOKENS_PER_CHAR = 0.25\n",
    "EMBEDDING_INPUT_SIZE = 512 # Mxbai-Embedding max input size\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL, model_kwargs={\"device\": \"cuda:0\"})\n",
    "random.seed(111)\n",
    "\n",
    "with open(f\"{DATA_DIR}/{SPLIT}.json\") as f:\n",
    "    datapoints = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bcdaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': 'https://web.archive.org/web/20230629073625/https://leadstories.com/hoax-alert/2023/06/fact-check-photos-do-not-prove-hobby-lobby-is-selling-satanic-statues.html',\n",
       " 'date': '2023-06-13',\n",
       " 'label': 'Refuted',\n",
       " 'location': 'US',\n",
       " 'questions': [{'input_images': [],\n",
       "   'answers': [{'answer_type': 'Extractive',\n",
       "     'answer_text': 'Hobby Lobby Stores, Inc., formerly Hobby Lobby Creative Centers, is an American retail company. It owns a chain of arts and crafts stores with a volume of over $5 billion in 2018.',\n",
       "     'source_url': 'https://en.wikipedia.org/wiki/Hobby_Lobby',\n",
       "     'source_medium': 'Web text'}],\n",
       "   'question': 'What is Hobby Lobby?',\n",
       "   'answer_method': 'Text-search',\n",
       "   'question_type': ['Text-related']},\n",
       "  {'input_images': ['6787dee1e2f02e5f4981b14e#INPUT#1#0.jpg',\n",
       "    '6787dee1e2f02e5f4981b14e#INPUT#1#1.jpg',\n",
       "    '6787dee1e2f02e5f4981b14e#INPUT#1#2.jpg',\n",
       "    '6787dee1e2f02e5f4981b14e#INPUT#1#3.jpg'],\n",
       "   'answers': [{'answer_type': 'Abstractive',\n",
       "     'answer_text': 'They are AI images created by Waster_Space. This is their comment on the images: Hobby Lobby if they had \"Satanic\" merchandise...(literally done in 5 mins...if I had known the images would be shared so many times, I would have spent more time on them)',\n",
       "     'source_url': 'https://www.artzone.ai/images/7f6126f1-967e-4c79-860f-f19a6eef290f',\n",
       "     'source_medium': 'Web text'}],\n",
       "   'question': 'What stores are these images from?',\n",
       "   'answer_method': 'Text-search',\n",
       "   'question_type': ['Image-related']}],\n",
       " 'justification': 'The claim is refuted by proving that the images were created with AI by Waster_Space for satirical purposes.',\n",
       " 'claim_text': 'Photos show that the craft store chain Hobby Lobby is selling demonic statues. ',\n",
       " 'claim_images': ['6787dee1e2f02e5f4981b14e#CLAIM#0.jpg',\n",
       "  '6787dee1e2f02e5f4981b14e#CLAIM#1.jpg',\n",
       "  '6787dee1e2f02e5f4981b14e#CLAIM#2.jpg',\n",
       "  '6787dee1e2f02e5f4981b14e#CLAIM#3.jpg'],\n",
       " 'metadata': {'speaker': 'Carousel Studios',\n",
       "  'transcription': '',\n",
       "  'media_source': '',\n",
       "  'original_claim_url': '',\n",
       "  'reporting_source': 'Facebook ',\n",
       "  'claim_types': ['Event/Property Claim'],\n",
       "  'fact_checking_strategies': ['Written Evidence',\n",
       "   'Reverse Image Search',\n",
       "   'Fact-checker Reference'],\n",
       "  'modality': 'Image-text',\n",
       "  'refuting_reasons': ['Misuse of images'],\n",
       "  'image_misuse_types': ['Out-of-context'],\n",
       "  'image_used': 'Yes'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3b6ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cee94f9d19b478e96f82a4addcc1147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for CLAIM_ID in tqdm(range(0,len(datapoints))):# Naive version with \\n concatenated url2texts:   \n",
    "    # skip if f\"{DATA_DIR}/data_store/vecstore/{SPLIT}/4k/{CLAIM_ID}\" exists\n",
    "    if os.path.exists(f\"{DATA_DIR}/vector_store/{SPLIT}/{CROP_SIZE_STR}_{EMBEDDING_NAME}/{CLAIM_ID}\"):\n",
    "        continue\n",
    "\n",
    "    os.makedirs(f\"{DATA_DIR}/vector_store/{SPLIT}/{CROP_SIZE_STR}_{EMBEDDING_NAME}/{CLAIM_ID}\")\n",
    "\n",
    "    datapoint = datapoints[CLAIM_ID]\n",
    "    claim = datapoint[\"claim_text\"]\n",
    "    # display(Markdown(\"### ðŸ—¯ï¸ \" + claim + \" [\" + datapoint[\"label\"] + \"]\"))\n",
    "    docstore = []\n",
    "    # /mnt/data/factcheck/averimatec/knowledge_store/val/text_related/text_related_store_text_val\n",
    "    for line in open(f\"{DATA_DIR}/knowledge_store/{SPLIT}/text_related/text_related_store_text_{SPLIT}/{CLAIM_ID}.json\"):\n",
    "        docstore.append(json.loads(line))\n",
    "\n",
    "    documents = [\n",
    "        Document(\n",
    "            page_content=\" \".join(doc[\"url2text\"]),\n",
    "            metadata={\n",
    "                \"url\": doc[\"url\"],\n",
    "                # \"sentences\": doc[\"url2text\"]\n",
    "            },\n",
    "        )\n",
    "        for doc in docstore\n",
    "    ]\n",
    "\n",
    "    chunks = []\n",
    "    for doc in docstore:\n",
    "        if not doc[\"url2text\"]:\n",
    "            continue\n",
    "        buffer = \"\"\n",
    "        for i, sentence in enumerate(doc[\"url2text\"]):\n",
    "            if (\n",
    "                i == len(doc[\"url2text\"]) - 1\n",
    "                or len(buffer) + len(sentence) >= EMBEDDING_INPUT_SIZE / TOKENS_PER_CHAR\n",
    "            ):\n",
    "                context_before = \"\"\n",
    "                if chunks and chunks[-1].metadata[\"url\"] == doc[\"url\"]:\n",
    "                    chunks[-1].metadata[\"context_after\"] = buffer\n",
    "                    context_before = chunks[-1].page_content\n",
    "                chunks.append(\n",
    "                    Document(\n",
    "                        page_content=buffer,\n",
    "                        metadata={\"url\": doc[\"url\"], \"context_before\": context_before, \"context_after\": \"\"},\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                buffer = \"\"\n",
    "            buffer += sentence + \" \"\n",
    "    # chunk the documents into smaller pieces\n",
    "    chid = random.randint(0, len(chunks))\n",
    "\n",
    "    # display(Markdown(chunks[chid].metadata[\"context_before\"]))\n",
    "    # display(Markdown(chunks[chid].page_content))\n",
    "    # display(Markdown(chunks[chid].metadata[\"context_after\"]))\n",
    "\n",
    "    # print(chunks[chid].page_content)\n",
    "    retriever = BM25Retriever.from_documents(\n",
    "        chunks, k=CROP_SIZE\n",
    "    )\n",
    "    chunks_pruned = retriever.invoke(claim)\n",
    "    db = FAISS.from_documents(chunks_pruned, embeddings)\n",
    "    db.save_local(f\"{DATA_DIR}/vector_store/{SPLIT}/{CROP_SIZE_STR}_{EMBEDDING_NAME}/{CLAIM_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df36672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrade sentence_transformers and transformers to the latest version\n",
    "%pip install -U sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which device embeddings use\n",
    "import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.current_device(), torch.cuda.get_device_name(0))\n",
    "print(torch.__version__)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"google/embeddinggemma-300m\")\n",
    "#make sure the embeddings are on cuda\n",
    "print(embeddings.client.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8d8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
